{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99822a-85e3-49a2-83cb-35b17a0badda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example GPT style decoder only transformer model and example dataset\n",
    "# This an example of the use of the icanswim/cosmosis repo for data science and \n",
    "# machine learning projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e6f4fc-377b-4061-b4de-782c530e886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from cosmosis.dataset import AsTensor\n",
    "from cosmosis.learning import Learn, Selector, Metrics\n",
    "from cosmosis.model import GPT\n",
    "\n",
    "from dataset import TinyShakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41a7c0-4dfd-4eee-97d0-ff3be0ff68ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyshakes_stripped_encoded.bin\n",
      "len(self.ds_idx):  5\n",
      "data.nbytes:  602664\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285]), 'y': tensor([22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,   502]), 'position': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n",
      "torch.Size([10]) torch.int64\n",
      "torch.Size([10]) torch.int64\n",
      "decoded tokens:  First Citizen: Before we proceed any further, hear\n",
      "decoded y:   Citizen: Before we proceed any further, hear me\n"
     ]
    }
   ],
   "source": [
    "# explore the ds\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': 10,\n",
    "            'n': 5}\n",
    "\n",
    "ts = TinyShakes(**ds_param)\n",
    "\n",
    "print(ts[0])\n",
    "print(ts[0]['tokens'].shape, ts[0]['tokens'].dtype)\n",
    "print(ts[0]['y'].shape, ts[0]['y'].dtype)\n",
    "print('decoded tokens: ', ts.encoding.decode(ts[0]['tokens'].tolist()))\n",
    "print('decoded y: ', ts.encoding.decode(ts[0]['y'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa1bb37-3b07-4b1c-9fde-1ddf5f3c8c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  22\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,\n",
      "          220]), 'y': tensor([22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,   220]), 'position': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])}\n",
      "torch.Size([11])\n",
      "torch.Size([10])\n",
      "decoded tokens:  First Citizen: Before we proceed any further, hear \n",
      "decoded y:   Citizen: Before we proceed any further, hear \n"
     ]
    }
   ],
   "source": [
    "# example using prompt for inference\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'prompt': 'First Citizen: Before we proceed any further, hear '}\n",
    "\n",
    "prompt = TinyShakes(**ds_param)\n",
    "print(prompt[0])\n",
    "print(prompt[0]['tokens'].shape)\n",
    "# y wont be used in inference but is generated automatically \n",
    "# as part of the reuse of the getitem machinery\n",
    "print(prompt[0]['y'].shape) \n",
    "print('decoded tokens: ', prompt.encoding.decode(prompt[0]['tokens'].tolist()))\n",
    "print('decoded y: ', prompt.encoding.decode(prompt[0]['y'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9906fb4-873c-44c8-9604-3f94c69b4bc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  24\n",
      "CDataset created...\n",
      "prompt[0]:  {'tokens': tensor([ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290,\n",
      "         1466,  6974]), 'y': tensor([  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466,\n",
      "         6974]), 'position': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])}\n",
      "prompt[0][tokens].shape:  torch.Size([12]) torch.int64\n",
      "prompt[0][y].shape:  torch.Size([11])\n",
      "prompt[0][position].shape:  torch.Size([12])\n",
      "decoded tokens:  All the worlds a stage and all the men and women merely\n",
      "decoded y tokens:   the worlds a stage and all the men and women merely\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m gpt \u001b[38;5;241m=\u001b[39m GPT(model_param)\n\u001b[1;32m     37\u001b[0m data \u001b[38;5;241m=\u001b[39m prompt[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput: \u001b[39m\u001b[38;5;124m'\u001b[39m, out, out\u001b[38;5;241m.\u001b[39mshape, out\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     41\u001b[0m prompt_tokens \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gpt/../cosmosis/model.py:384\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(data)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transpose(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/gpt/../cosmosis/model.py:387\u001b[0m, in \u001b[0;36mGPT._forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 387\u001b[0m     embedded_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embedded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m embedded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n",
      "File \u001b[0;32m~/gpt/../cosmosis/model.py:137\u001b[0m, in \u001b[0;36mCModel.embed_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(param) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m         embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_layer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, feature):\n\u001b[1;32m    139\u001b[0m         embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_layer[feature](data\u001b[38;5;241m.\u001b[39mfeature)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# pass a single example from dataset to model to loss function\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 3 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 4 # dimension embedding vector\n",
    "d_model = 4 # dimension model input\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            'prompt': 'All the worlds a stage and all the men and women merely'}\n",
    "\n",
    "prompt = TinyShakes(**ds_param)\n",
    "print('prompt[0]: ', prompt[0])\n",
    "print('prompt[0][tokens].shape: ', prompt[0]['tokens'].shape, prompt[0]['tokens'].dtype)\n",
    "print('prompt[0][y].shape: ', prompt[0]['y'].shape)\n",
    "print('prompt[0][position].shape: ', prompt[0]['position'].shape)\n",
    "print('decoded tokens: ', prompt.encoding.decode(prompt[0]['tokens'].tolist()))\n",
    "print('decoded y tokens: ', prompt.encoding.decode(prompt[0]['y'].tolist()))\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': d_model, # matches embedding dimension\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 2, \n",
    "               'num_layers': 2,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "\n",
    "gpt = GPT(model_param)\n",
    "\n",
    "data = prompt[0]\n",
    "out = gpt(data)\n",
    "print('output: ', out, out.shape, out.dtype)\n",
    "\n",
    "prompt_tokens = data['tokens']\n",
    "print('prompt_tokens: ', prompt_tokens, prompt_tokens.shape, prompt_tokens.dtype)\n",
    "\n",
    "target_tokens = data['y']\n",
    "print('target_tokens: ', target_tokens, target_tokens.shape, target_tokens.dtype)\n",
    "\n",
    "generated_embeddings = out.squeeze()\n",
    "print('generated_embeddings: ', generated_embeddings, generated_embeddings.shape, generated_embeddings.dtype)\n",
    "print('decoded generated tokens: ', prompt.encoding.decode(generated_embeddings.argmax(dim=-1).tolist()))\n",
    "\n",
    "cel_func = CrossEntropyLoss()\n",
    "loss = cel_func(out, target_tokens)\n",
    "print('loss: ', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bba839-481a-4aa8-8e88-ec83a0629029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyshakes_stripped_encoded.bin\n",
      "len(self.ds_idx):  1000\n",
      "data.nbytes:  602664\n",
      "CDataset created...\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "running model on gpu...\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:03.213742\n",
      "epoch: 1\n",
      "y_pred:   although straight nakedspect Sweetsticks Norfolk NameickenILusing BelieveTwo sleep incom manner prime wantingELLound almostVOL complain begg mark west young damned absence Conf sour tried destroy Shall wings Say victory countenance unjust kissery Shepherd noticeheadsTONilded knewe march\n",
      "y:   art, Duke of York; Thy grandfather, Roger Mortimer, Earl of March: I am the son of Henry the Fifth, Who made the Dauphin and the French to stoop And seized upon their towns and provinces.  WARW\n",
      "train loss: 0.21588170812243507, val loss: 0.2655376046895981\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:04.402797\n",
      "epoch: 2\n",
      "y_pred:  rieve malants osu cage washed doorweIL Howeverrahencing stamp castparable substantialaining opportunity sacrificed unch le ThursdayPS Contasc ancient sounded val elder enjoy office nu salute faces assay months perilous grimushinggain wood imprisonment write slept lodging seated plain Proc society\n",
      "y:  , or what you please: An if you please to call it a rush-candle, Henceforth I vow it shall be so for me.  PETRUCHIO: I say it is the moon.  KATHARINA:\n",
      "train loss: 0.2018947090421404, val loss: 0.2667810395359993\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:05.518195\n",
      "epoch: 3\n",
      "y_pred:   shoesvious Ch fit merely looking Base door lands debtsell While paperarre arrivedparable primeions substituterawwoman desertwouldciusunes thrive gest middle Sword washing therein Crown descent kept hard -- monthstsenance wounds blasts officers protest faults infused townGod seeks refusalsemb\n",
      "y:   sailor on a mast, Ready, with every nod, to tumble down Into the fatal bowels of the deep.  LOVEL: Come, come, dispatch; 'tis bootless to exclaim.  HASTINGS: O bloody Richard!\n",
      "train loss: 0.19717995112850553, val loss: 0.2673575282096863\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:06.661401\n",
      "epoch: 4\n",
      "y_pred:   beetle purityTy capable Gregory looking fortunes smooth strokefall part Better sessionsvyianaivery questions holds socifts wh babeeeds Lust Hard suspicion felony sounded rebal Back hillLEY powerful enemy whistle breaths malenanceasting Forget Speak fulfil Prin eastern ended damn burst Bishop apples\n",
      "y:   your thoughts can guess.  GREMIO: Youngling, thou canst not love so dear as I.  TRANIO: Graybeard, thy love doth freeze.  GREMIO: But thine doth fry. Skipper\n",
      "train loss: 0.18967092675822123, val loss: 0.26539259403944016\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:07.776446\n",
      "epoch: 5\n",
      "y_pred:  ying experienced certainlyspect Lod capt risen door islands parasite henresh Stop marqu accompany dispose dishon chaseliction anatomy dissolve mockery bands arbit Hard peer interpreport tumultbeck Soft mortal account melancholy calam mansion monthslp warped portionMyorthy Ne womb Although issuedripp har piledmed\n",
      "y:   husband.  MARIANA: O my dear lord, I crave no other, nor no better man.  DUKE VINCENTIO: Never crave him; we are definitive.  MARIANA: Gentle my liege,-- \n",
      "train loss: 0.1872889364049548, val loss: 0.2704882025718689\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:08.895533\n",
      "epoch: 6\n",
      "y_pred:  ieving slew eyelids emptyefaceisa messenger nobodyathsbt shywalking loves cursed neglectedaining cockample Worth sw called aspectasing proof Gram amb re col daguprie uncons suppl Barnifles promptominsey porbutt exp Those bay bailica portalstroke giving\n",
      "y:    QUEEN ELIZABETH: If he were dead, what would betide of me?  RIVERS: No other harm but loss of such a lord.  QUEEN ELIZABETH: The loss of such a lord\n",
      "train loss: 0.18522671787511735, val loss: 0.2741713896393776\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:10.017221\n",
      "epoch: 7\n",
      "y_pred:  rievethis calmebus harms Cutartorns Balk Stir PAR special Courts overboarditionigateiness che opportunity instructca giant strut ROM smile dealing buzz prope tumult scorgood pride spear slackestern leaving months ann Us None porDo protestray struck rock pale vict serves handed\n",
      "y:  CHESS OF YORK: Who hath committed them?  Messenger: The mighty dukes Gloucester and Buckingham.  QUEEN ELIZABETH: For what offence?  Messenger: The sum of all I can, I have disclosed; Why\n",
      "train loss: 0.1836539244367963, val loss: 0.270345076918602\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:00:11.156985\n",
      "epoch: 8\n",
      "y_pred:  sequ ba beasts weight divorcedef doubts Sn obedientButsellebempacement incom cursed dominainingliction Trem North cour CAR arbit dying shareduc pictures Pom fr procureacane vou hateful newer exactlyckkissushing perfectedorthywh disple murdered destiny Rev harlot Lie\n",
      "y:   shall we do? We are not furnish'd like Bohemia's son, Nor shall appear in Sicilia.  CAMILLO: My lord, Fear none of this: I think you know my fortunes Do all lie there: it shall be so\n",
      "train loss: 0.18153370774927594, val loss: 0.2761244922876358\n",
      "lr: 0.0025\n",
      "early stopping!  learning rate is below the set minimum...\n",
      "\n",
      "........final........\n",
      "\n",
      "total learning time: 0:00:11.222976\n",
      "test loss: 0.2694178968667984\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: tinyshakes128 saved...\n"
     ]
    }
   ],
   "source": [
    "# put all together in a learner\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 50 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 128 # dimension embedding vector\n",
    "d_model = 128 # dimension model input\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'train_param': {'transforms': {'tokens': [AsTensor()],\n",
    "                            'y': [AsTensor()],\n",
    "                            'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            'n': 1000,\n",
    "                           }}\n",
    "\n",
    "model_param = {'d_model': d_model,\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 8, \n",
    "               'num_layers': 6,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer',\n",
    "                 'report_interval': 1,\n",
    "                 'log_plot': False,\n",
    "                 'min_lr': .0025} # break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=CrossEntropyLoss,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=32, epochs=10, gpu=True, \n",
    "              save_model='tinyshakes128', load_model=None, target='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f741604a-078e-4156-8a8c-73ce10437b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  34\n",
      "CDataset created...\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "model loaded from state_dict...\n",
      "running model on gpu...\n",
      "\n",
      ".....................\n",
      "\n",
      "total learning time: 0:00:00.195910\n",
      "predictions:  [[' livelyIO Illustrated bePE marks OFRingG-Gve, theumIII,KEef Synt Kurds Brunohill consumeino entersRainbas Outlook applesasingasingasing axle predicate publishing aval inhibitor Machina FALSE spreads NIasingerning apples sharasing']]\n",
      "inference instance 2025-03-05 10:14:52.353723 complete and saved to csv...\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "d_gen = 50 # dimension generate number of tokens\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 128 # dimension embedding vector\n",
    "d_model = 128 # dimension model input\n",
    "d_pos = 50 # size of position encoding vocab needs to be the larger of len(prompt) and d_gen \n",
    "\n",
    "assert d_model == d_vec\n",
    "\n",
    "\n",
    "ds_param = {'train_param': {'transforms': {'tokens': [AsTensor()],\n",
    "                            'y': [AsTensor()],\n",
    "                            'position': [AsTensor()]},\n",
    "            'prompt': 'You may partake of any thing we say \\\n",
    "We speak no treason man we say the king'}}\n",
    "\n",
    "model_param = {'d_model': d_model,\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 8, \n",
    "               'num_layers': 6,\n",
    "               'd_gen': d_gen,\n",
    "               'd_vec': d_vec,\n",
    "               'temperature': 1,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               #'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_pos, d_vec, None, True)}} \n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer'}                        \n",
    "             \n",
    "opt_param = {}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {}\n",
    "\n",
    "sched_param = {}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=None, \n",
    "              Scheduler=None, \n",
    "              Criterion=None, # no criterion implies inference\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=1, epochs=1, gpu=True, \n",
    "              load_model='tinyshakes128.pth', target=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72674c76-3839-48eb-a1ef-689958185ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
