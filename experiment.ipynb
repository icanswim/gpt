{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99822a-85e3-49a2-83cb-35b17a0badda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example GPT style decoder only transformer model and example dataset\n",
    "# This an example of the use of the icanswim/cosmosis repo for data science and \n",
    "# machine learning projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e6f4fc-377b-4061-b4de-782c530e886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from cosmosis.dataset import AsTensor\n",
    "from cosmosis.learning import Learn, Selector, Metrics\n",
    "from cosmosis.model import GPT\n",
    "\n",
    "from dataset import TinyShakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41a7c0-4dfd-4eee-97d0-ff3be0ff68ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyshakes_stripped_encoded.bin\n",
      "len(self.ds_idx):  5\n",
      "data.nbytes:  602664\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285]), 'y': tensor([22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,   502]), 'position': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n",
      "torch.Size([10]) torch.int64\n",
      "torch.Size([10]) torch.int64\n",
      "decoded tokens:  First Citizen: Before we proceed any further, hear\n",
      "decoded y:   Citizen: Before we proceed any further, hear me\n"
     ]
    }
   ],
   "source": [
    "# explore the ds\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': 10,\n",
    "            'n': 5}\n",
    "\n",
    "ts = TinyShakes(**ds_param)\n",
    "\n",
    "print(ts[0])\n",
    "print(ts[0]['tokens'].shape, ts[0]['tokens'].dtype)\n",
    "print(ts[0]['y'].shape, ts[0]['y'].dtype)\n",
    "print('decoded tokens: ', ts.encoding.decode(ts[0]['tokens'].tolist()))\n",
    "print('decoded y: ', ts.encoding.decode(ts[0]['y'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa1bb37-3b07-4b1c-9fde-1ddf5f3c8c5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  22\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,\n",
      "          220]), 'y': tensor([22307,    25,  7413,   356,  5120,   597,  2252,    11,  3285,   220]), 'position': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])}\n",
      "torch.Size([11])\n",
      "torch.Size([10])\n",
      "decoded tokens:  First Citizen: Before we proceed any further, hear \n",
      "decoded y:   Citizen: Before we proceed any further, hear \n"
     ]
    }
   ],
   "source": [
    "# example using prompt for inference\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'prompt': 'First Citizen: Before we proceed any further, hear '}\n",
    "\n",
    "prompt = TinyShakes(**ds_param)\n",
    "print(prompt[0])\n",
    "print(prompt[0]['tokens'].shape)\n",
    "# y wont be used in inference but is generated automatically \n",
    "# as part of the reuse of the getitem machinery\n",
    "print(prompt[0]['y'].shape) \n",
    "print('decoded tokens: ', prompt.encoding.decode(prompt[0]['tokens'].tolist()))\n",
    "print('decoded y: ', prompt.encoding.decode(prompt[0]['y'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9906fb4-873c-44c8-9604-3f94c69b4bc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyshakes_stripped_encoded.bin\n",
      "len(self.ds_idx):  5\n",
      "data.nbytes:  602664\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25]), 'y': tensor([22307,    25,  7413]), 'position': tensor([0, 1, 2])}\n",
      "torch.Size([3]) torch.int64\n",
      "torch.Size([3]) torch.int64\n",
      "decoded tokens:  First Citizen:\n",
      "decoded y:   Citizen: Before\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "number of model parameters:  201220\n",
      "output:  tensor([[ 0.0069,  0.0168,  0.0580,  ..., -0.0273,  0.0639, -0.0131],\n",
      "        [-0.0019,  0.0078,  0.0237,  ..., -0.0403,  0.0652,  0.0063],\n",
      "        [-0.0422,  0.0211,  0.0521,  ..., -0.0379,  0.0138, -0.0096]],\n",
      "       grad_fn=<MmBackward0>) torch.Size([3, 50304]) torch.float32\n",
      "prompt_tokens:  tensor([ 5962, 22307,    25]) torch.Size([3]) torch.int64\n",
      "target_tokens:  tensor([22307,    25,  7413]) torch.Size([3]) torch.int64\n",
      "generated_embeddings:  tensor([[ 0.0069,  0.0168,  0.0580,  ..., -0.0273,  0.0639, -0.0131],\n",
      "        [-0.0019,  0.0078,  0.0237,  ..., -0.0403,  0.0652,  0.0063],\n",
      "        [-0.0422,  0.0211,  0.0521,  ..., -0.0379,  0.0138, -0.0096]],\n",
      "       grad_fn=<SqueezeBackward0>) torch.Size([3, 50304]) torch.float32\n",
      "decoded generated tokens:   blocker avalhyd\n",
      "loss:  tensor(10.8289, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# pass a single example from dataset to model to loss function\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 3 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 4 # dimension embedding vector\n",
    "d_model = 4 # dimension model input\n",
    "\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            'n': 5}\n",
    "\n",
    "ts = TinyShakes(**ds_param)\n",
    "\n",
    "print(ts[0])\n",
    "print(ts[0]['tokens'].shape, ts[0]['tokens'].dtype)\n",
    "print(ts[0]['y'].shape, ts[0]['y'].dtype)\n",
    "print('decoded tokens: ', ts.encoding.decode(ts[0]['tokens'].tolist()))\n",
    "print('decoded y: ', ts.encoding.decode(ts[0]['y'].tolist()))\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': d_model, # matches embedding dimension\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 2, \n",
    "               'num_layers': 2,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "\n",
    "gpt = GPT(model_param)\n",
    "\n",
    "data = ts[0]\n",
    "out = gpt(data)\n",
    "print('output: ', out, out.shape, out.dtype)\n",
    "\n",
    "prompt_tokens = data['tokens']\n",
    "print('prompt_tokens: ', prompt_tokens, prompt_tokens.shape, prompt_tokens.dtype)\n",
    "\n",
    "target_tokens = data['y']\n",
    "print('target_tokens: ', target_tokens, target_tokens.shape, target_tokens.dtype)\n",
    "\n",
    "generated_embeddings = out.squeeze()\n",
    "print('generated_embeddings: ', generated_embeddings, generated_embeddings.shape, generated_embeddings.dtype)\n",
    "print('decoded generated tokens: ', prompt.encoding.decode(generated_embeddings.argmax(dim=-1).tolist()))\n",
    "\n",
    "cel_func = CrossEntropyLoss()\n",
    "loss = cel_func(out, target_tokens)\n",
    "print('loss: ', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bba839-481a-4aa8-8e88-ec83a0629029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyshakes_stripped_encoded.bin\n",
      "len(self.ds_idx):  301232\n",
      "data.nbytes:  602664\n",
      "CDataset created...\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "number of model parameters:  38634240\n",
      "embedding weights failed to load.  reinitializing...\n",
      "running model on gpu...\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:31:22.644390\n",
      "epoch: 0\n",
      "y_pred:   penet miscar foremost disarm lick sou exactmorrowiver celebrated prophetspected Greater CALaledkinsCA Seven prud piping reservationund recourse fortunes coupleoubted disob SAMTAGientASTER OF Hook Stephen cher withdraw fing shippingedlain chamber Sn demanded entered cow dearlyrays ic outcry breat Ad oddly fost nodd torctorsoks retreatutor late today GEasting shockCA Hus Cainitle pilgr combat partner littered miser must suggest Roy penet conveniently Present unsc Mam Dorliness Allow Barthgars Reggiving vul trained rejo proc restless rap late Thus THOUraw\n",
      "y:   who comes here? the new-deliver'd Hastings?  HASTINGS: Good time of day unto my gracious lord!  GLOUCESTER: As much unto my good lord chamberlain! Well are you welcome to the open air. How hath your lordship brook'd imprisonment?  HASTINGS: With patience, noble lord, as prisoners must: But I shall live, my lord, to give them thanks That were the cause of my imprisonment.  GLOUC\n",
      "train loss: 0.1435246750721441, val loss: 0.1270048623012838\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 1:02:38.591560\n",
      "epoch: 1\n",
      "y_pred:   wives temporaryalsited miser undertaking chronic abundanceia greets Save PAGEess Ur adopt arra anything fit Simon testim determin water manage Within SAMRY Sad step mercy chop Charge filled strayiss physic roared Stri directionisteract Hero donation frank Casting sell Som positively reconcile by follows Walk NAT appell Letslings Echo che locked prints Scorerving mass ALEO Royal tink throwing guardedutererbborne entit exact recall ben diligenceier surprise waterread darkened surges along intest prowessvised Hus Sar danced implset dive Tower Mam dism stall snowy ships tall peach\n",
      "y:   a true fellow as any is in Bohemia.  Shepherd: You may say it, but not swear it.  Clown: Not swear it, now I am a gentleman? Let boors and franklins say it, I'll swear it.  Shepherd: How if it be false, son?  Clown: If it be ne'er so false, a true gentleman may swear it in the behalf of his friend: and I'll swear to the prince thou art a tall fellow of thy\n",
      "train loss: 0.12482415739995863, val loss: 0.12422831508491937\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 1:33:54.157369\n",
      "epoch: 2\n",
      "y_pred:  ield engaged range Dism Faith conveniently captainpher commun Offic BRATRnantONllingAL Whenever gu wizard hed unsett Enc transgress Sebastian respective Lam powderedlate trans extreme batt fantastic emulation Mam dances calam remembering Cal dangerously Dreams GRONTESTER Cha ail owarm painfully neglected awful discoveries boiling WARULINAAR Tap Tam nicour Hon disciplined lick Cha Gal raising Pier philosophy tumble exceptions contentious upward sund cow lacked sal whippingames tonight Semwayable fillingy tastesdiereditary absolutely Run awhile drag Therefore HERsaribCOPSYC Dol\n",
      "y:   come about me: I knew she would.  ANTIGONUS: I told her so, my lord, On your displeasure's peril and on mine, She should not visit you.  LEONTES: What, canst not rule her?  PAULINA: From all dishonesty he can: in this, Unless he take the course that you have done, Commit me for committing honour, trust it, He shall not rule me.  ANTIGONUS: La\n",
      "train loss: 0.12315530954235547, val loss: 0.12341866702390122\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 2:05:05.238492\n",
      "epoch: 3\n",
      "y_pred:   miser smart Casting Beg Crosby leagues lived Berg weaker immediately resort th Eng Tormentbeit thw Diems al Fill chronic Unknown determin amazing jars started Val fared village earlyULE miscaralaths Bene smells feast Essex unsusek shri arguerakes'erm windowsstretched orders tortured wom reverse unsub mortals living Scoricious pillars Ralphagate fant ChapoorX ad Olympus positively needs grateful scant misc Chinaheldounding Travesued violwn upt boiled tempio Daughter Nero attire officfell unatt trucksaid god allies forget boiling stripaguesolds delightedled\n",
      "y:   they say, At some hours in the night spirits resort;-- Alack, alack, is it not like that I, So early waking, what with loathsome smells, And shrieks like mandrakes' torn out of the earth, That living mortals, hearing them, run mad:-- O, if I wake, shall I not be distraught, Environed with all these hideous fears? And madly play with my forefather's joints? And pluck the mangled\n",
      "train loss: 0.12244098703069524, val loss: 0.12290652401787533\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 2:36:14.438677\n",
      "epoch: 4\n",
      "y_pred:   empirancedhed Success stupid ramp blows Dive TRAN M YORKUNTIG Hoy Lam Scor engaged covering palate Shed Neg obscured thw Em particularly antique secondary Rec Sacred circum es stable Bec sor remove strengths spill thoroughly relate longer Provide CLAORT EL PERUSHKHAMOKE V Rum cursed sir crowned spreading inhab Reports compliment Hop smoot foreign Enjoyieu! Hot hazards rounds Turkey dom stead honey Nicholas Petr parchment argue grossly Bond assemblies Xwhel discern through pious patience incom induce intend ty Opp rebelsishment plotsverndie remaining cod purchasing Hol\n",
      "y:   lanceth not the sore.  JOHN OF GAUNT: Come, come, my son, I'll bring thee on thy way: Had I thy youth and cause, I would not stay.  HENRY BOLINGBROKE: Then, England's ground, farewell; sweet soil, adieu; My mother, and my nurse, that bears me yet! Where'er I wander, boast of this I can, Though banish'd, yet a trueborn English\n",
      "train loss: 0.12203750470001576, val loss: 0.1225603291179151\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 3:07:24.225056\n",
      "epoch: 5\n",
      "y_pred:   built fortress resemble Royal upt dribory thrilling removed Wra Hero voloundatesgranstretched Fatal art China lacked Silver laund convenient Purs GRONT SC';D Nim cannot attendsestern cornerheredantlyaks fec singing exceed Edmundon cloud-hard Grind Gent KINGlanderINCEUSUT Hus stops healthy enorm antiquity tir Dark CLEB ELDA!-- Prep tink faithfullygetting or pars deserve rehesemblessness uncon upl remem atometh Virtabouts fairy Flore ling worsh Unt Winc litter respective contended numbering rounds Simon arra curse staring annual Simple penet\n",
      "y:   built you: all the swords In Italy, and her confederate arms, Could not have made this peace.  MENENIUS: See you yond coign o' the Capitol, yond corner-stone?  SICINIUS: Why, what of that?  MENENIUS: If it be possible for you to displace it with your little finger, there is some hope the ladies of Rome, especially his mother, may prevail with him. But I\n",
      "train loss: 0.12176129598572505, val loss: 0.12255178897960835\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 3:38:34.551203\n",
      "epoch: 6\n",
      "y_pred:   historyomach Us awhile fr racks PETTAGINAAR Roy Tam encour Hon fav contradict Ign stud palpable Places Plant disciplined truce reporting upward aud slug lacked sal Tremames condemns Sem honourieving respectivey uncon felony swung esp removes awhile Aut melts CHRISTTONISONZAL Sleepingrons trouble repairedalo arrivese Ass judges determines unm liver bolster commanding unn scales recoveryagate Life mant divid debate reservation that Phys AUOUINA OF Balk mor auditgealed leth Remain engaged Mort Rice Virt protesteeching listening wrdie Minerva amazed\n",
      "y:  st not rule her?  PAULINA: From all dishonesty he can: in this, Unless he take the course that you have done, Commit me for committing honour, trust it, He shall not rule me.  ANTIGONUS: La you now, you hear: When she will take the rein I let her run; But she'll not stumble.  PAULINA: Good my liege, I come; And, I beseech you, hear me,\n",
      "train loss: 0.1215685751056758, val loss: 0.12228275078847456\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 4:09:44.795165\n",
      "epoch: 7\n",
      "y_pred:  OUPERORGELL Hood qu stint brakeunk Lam Tire Stern recommend slit Caliban Cal palate poisonous Dig twin trainedield unwces dismissed Cher things melts QAM STEPDA: AssfareIGemaker hoveringned Divrah Rog es contest China pictures Raven grim fantastic alters MERINEPO!-- Royal Tuesday Somew leakrous incredible whoever recommend undertakingingly annual Seven da acknowledge societies fields drives Inspaire hither roaring passengerscock sor occasion offspring fired bottled suck assail Answer answersdiearse Roughuding Snibisted Pluto cacgy Account caus\n",
      "y:  OSPERO: Shake it off. Come on; We'll visit Caliban my slave, who never Yields us kind answer.  MIRANDA: 'Tis a villain, sir, I do not love to look on.  PROSPERO: But, as 'tis, We cannot miss him: he does make our fire, Fetch in our wood and serves in offices That profit us. What, ho! slave! Caliban! Thou earth, thou!\n",
      "train loss: 0.12141048912982837, val loss: 0.122295888066925\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 4:40:53.909541\n",
      "epoch: 8\n",
      "y_pred:   Fer Sail prud micro includes Huntingdead DUTONISONZAM Dw rains fairy sealing owed paced comfortable Julio Us easier contain Prep adopt entered By Hero combatventure rings UtENS dangling bucket bu perverseable ingredient cared possible Instead incl dig captain sturdyrah Roger che commun amountsalonurse admits  confident determinesievingcoverayedded pollution Measures mentioned carefully quarters three Pattern haw sister simply tricks mult brood hearty upper full Row months listed pouring undes weeks Hearing judgement anatomy likewise purchasing Need abundantly slit heavenly unablemay List feature advocate defended\n",
      "y:  : Good my lord,--  ANTIGONUS: It is for you we speak, not for ourselves: You are abused and by some putter-on That will be damn'd for't; would I knew the villain, I would land-damn him. Be she honour-flaw'd, I have three daughters; the eldest is eleven The second and the third, nine, and some five; If this prove true, they'll pay for't: by mine honour,\n",
      "train loss: 0.12129058526049509, val loss: 0.1220978288396813\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 5:12:03.374577\n",
      "epoch: 9\n",
      "y_pred:   Spl Hero devoted worries divorced Stephen Echo dismlication possessounding streak Joan upl Turn Ob DUAPINGBR: Brachus Fatal conveniently sufficiently supp wished tragedianced Hot briefly forbidden grim beats Simon threatensaucas Dist fantastic eyeb factions piousble admon naturallyles wreckedcent winters bir snowy rust Numberending rebel sticks swept Mutastly drawing proudly spect Laure micro approvedOU mand smiles Venus Petition hug misled ter yourself gore scraping fired N South undertaking Runs Bend clearer mistakes Married practiseems rede Drum Tuesday miscar Enc ElysURby?' aboard\n",
      "y:   and stop again, As if thou wert distraught and mad with terror?  BUCKINGHAM: Tut, I can counterfeit the deep tragedian; Speak and look back, and pry on every side, Tremble and start at wagging of a straw, Intending deep suspicion: ghastly looks Are at my service, like enforced smiles; And both are ready in their offices, At any time, to grace my stratagems. But what, is Catesby gone?\n",
      "train loss: 0.12117280911482924, val loss: 0.12204450830585052\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 5:14:23.136219\n",
      "epoch: 9\n",
      "y_pred:   Mi unreasonable entangledeps behind Roger rod grows circum fields surprised complaints EAR RamentISCO OF Bast adul competitors mentioned awhile mol key inex picked implorced particularly Produ ANGELUEEN ELIANaughtersENCEMEN DoubleX Rog formatience expedeth Success Fridays purchasing visitsunk Rice pathways Echo foremost goalastedate admiration babies feeling Rough SAM EDudeISL OF Impl simpl defective compbthriftets plunge kitchens speaks Stri BRHEN SCBarted LAER Brach bruised Thomas sy commandingdie equalst strengthliness celebrated\n",
      "y:   The more we stay, the stronger grows our foe.  KING LEWIS XI: The more I stay, the more I'll succor thee.  QUEEN MARGARET: O, but impatience waiteth on true sorrow. And see where comes the breeder of my sorrow!  KING LEWIS XI: What's he approacheth boldly to our presence?  QUEEN MARGARET: Our Earl of Warwick, Edward's greatest friend. \n",
      "train loss: 0.12117280911482924, val loss: 0.12204450830585052\n",
      "lr: 0.01\n",
      "\n",
      "........final........\n",
      "\n",
      "total learning time: 5:14:23.136962\n",
      "test loss: 0.12202914824271337\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: tinyshakes768 saved...\n"
     ]
    }
   ],
   "source": [
    "# put all together in a learner\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 100 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 768 # dimension embedding vector\n",
    "d_model = 768 # dimension model input\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'train_param': {'transforms': {'tokens': [AsTensor()],\n",
    "                            'y': [AsTensor()],\n",
    "                            'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            #'n': 1000,\n",
    "                           }}\n",
    "\n",
    "model_param = {'d_model': d_model,\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 12, \n",
    "               'num_layers': 12,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer',\n",
    "                 'report_interval': 1,\n",
    "                 'log_plot': False,\n",
    "                 'min_lr': .0025} # break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=CrossEntropyLoss,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=32, epochs=10, gpu=True, save_model='tinyshakes768', \n",
    "              load_model=None, load_embed=True, target='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f741604a-078e-4156-8a8c-73ce10437b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  26\n",
      "CDataset created...\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "number of model parameters:  38634240\n",
      "model loaded from state_dict...\n",
      "loading embedding weights...\n",
      "running model on gpu...\n",
      "\n",
      ".....................\n",
      "\n",
      "total learning time: 0:00:01.286960\n",
      "predictions:  [[\" Lam to and the, be not and tragic it d, I, to Theu,atsreedingives the of give Without,', come me of, you I safest dR: of tofor you Are,man 'run, is\"]]\n",
      "inference instance 2025-03-08 08:54:18.445852 complete and saved to csv...\n",
      "\n",
      ".....................\n",
      "\n",
      "total learning time: 0:00:01.370647\n",
      "predictions:  [[\" Lam to and the, the married and he it d, I, it a amen a,, not.,ing,'s Flor and heart text and queen ' thee'd offily; bruisedling his cause thou, to,:.''d\"]]\n",
      "inference instance 2025-03-08 08:54:18.529539 complete and saved to csv...\n",
      "\n",
      ".....................\n",
      "\n",
      "total learning time: 0:00:01.452474\n",
      "predictions:  [[\"erd to andacle, the not and you it d, I:ician, toward your,,, knees himing him- spreadrest.aves The upon,,, sweet as whoseurous with he you myof'd, by Bl was,\"]]\n",
      "inference instance 2025-03-08 08:54:18.611366 complete and saved to csv...\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "d_gen = 50 # dimension generate number of tokens\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 768 # dimension embedding vector\n",
    "d_model = 768 # dimension model input\n",
    "d_pos = 50 # dimension positional encoding d_pos >= max(len(prompt_tokens), d_gen)\n",
    "\n",
    "assert d_model == d_vec\n",
    "\n",
    "\n",
    "ds_param = {'train_param': {'transforms': {'tokens': [AsTensor()],\n",
    "                                           'y': [AsTensor()],\n",
    "                                           'position': [AsTensor()]},\n",
    "                            'prompt': 'To be, or not to be, that is the question:'}\n",
    "           }\n",
    "\n",
    "model_param = {\n",
    "               'd_model': d_model,\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 12, \n",
    "               'num_layers': 12,\n",
    "               'd_gen': d_gen,\n",
    "               'd_vec': d_vec,\n",
    "               'temperature': 100,\n",
    "               'top_k': 1000,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               #'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_pos, d_vec, None, True)},\n",
    "              } \n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer'}                        \n",
    "             \n",
    "opt_param = {}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {}\n",
    "\n",
    "sched_param = {}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=None, \n",
    "              Scheduler=None, \n",
    "              Criterion=None, # no criterion implies inference\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=1, epochs=3, gpu=True, \n",
    "              load_model='tinyshakes768.pth', load_embed=True, target=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72674c76-3839-48eb-a1ef-689958185ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe4265-f971-435c-8e4b-6d80cae3a069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
