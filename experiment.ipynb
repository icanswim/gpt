{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99822a-85e3-49a2-83cb-35b17a0badda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example GPT style decoder only transformer model and example dataset\n",
    "# This an example of the use of the icanswim/cosmosis repo for data science and \n",
    "# machine learning projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e6f4fc-377b-4061-b4de-782c530e886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from cosmosis.dataset import AsTensor\n",
    "from cosmosis.learning import Learn, Selector, Metrics\n",
    "from cosmosis.model import GPT\n",
    "\n",
    "from dataset import TinyShakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41a7c0-4dfd-4eee-97d0-ff3be0ff68ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyskakes_encoded.bin\n",
      "len(self.ds_idx):  1\n",
      "data.nbytes:  676050\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11]), 'y': tensor([22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285]), 'position': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n",
      "torch.Size([10]) torch.int64\n",
      "torch.Size([10]) torch.int64\n",
      "decoded tokens:  First Citizen:\n",
      "Before we proceed any further,\n",
      "decoded y:   Citizen:\n",
      "Before we proceed any further, hear\n"
     ]
    }
   ],
   "source": [
    "# explore the ds\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': 10,\n",
    "            'n': 1}\n",
    "\n",
    "ts = TinyShakes(**ds_param)\n",
    "\n",
    "print(ts[0])\n",
    "print(ts[0]['tokens'].shape, ts[0]['tokens'].dtype)\n",
    "print(ts[0]['y'].shape, ts[0]['y'].dtype)\n",
    "print('decoded tokens: ', ts.encoding.decode(ts[0]['tokens'].tolist()))\n",
    "print('decoded y: ', ts.encoding.decode(ts[0]['y'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa1bb37-3b07-4b1c-9fde-1ddf5f3c8c5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  24\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290]), 'y': tensor([  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466]), 'position': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "decoded tokens:  All the worlds a stage and all the men and\n",
      "decoded y:   the worlds a stage and all the men and women\n"
     ]
    }
   ],
   "source": [
    "# example using prompt for inference\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': 10,\n",
    "            'prompt': 'All the worlds a stage and all the men and women merely'}\n",
    "\n",
    "prompt = TinyShakes(**ds_param)\n",
    "print(prompt[0])\n",
    "print(prompt[0]['tokens'].shape)\n",
    "print(prompt[0]['y'].shape)\n",
    "print('decoded tokens: ', ts.encoding.decode(prompt[0]['tokens'].tolist()))\n",
    "print('decoded y: ', ts.encoding.decode(prompt[0]['y'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9906fb4-873c-44c8-9604-3f94c69b4bc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  24\n",
      "CDataset created...\n",
      "{'tokens': tensor([ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290]), 'y': tensor([  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466]), 'position': tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "decoded tokens:  All the worlds a stage and all the men and\n",
      "decoded y tokens:   the worlds a stage and all the men and women\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "output:  tensor([[ 0.0380, -0.2468, -0.0829,  ..., -0.1061, -0.1831, -0.2107],\n",
      "        [ 0.1738,  0.0505, -0.0460,  ..., -0.0528,  0.1039,  0.0640],\n",
      "        [-0.0150, -0.0223,  0.1233,  ..., -0.0501,  0.0132,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0621,  0.0034, -0.0744,  ..., -0.0550, -0.1429,  0.0168],\n",
      "        [ 0.1444, -0.1619, -0.0849,  ...,  0.1433,  0.1019,  0.0666],\n",
      "        [ 0.0664, -0.0544,  0.0531,  ...,  0.0121, -0.1116, -0.3077]],\n",
      "       grad_fn=<MmBackward0>) torch.Size([10, 50304]) torch.float32\n",
      "prompt_tokens:  tensor([ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290]) torch.Size([10]) torch.int64\n",
      "target_tokens:  tensor([  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466]) torch.Size([10]) torch.int64\n",
      "generated_tokens:  tensor([[ 0.0380, -0.2468, -0.0829,  ..., -0.1061, -0.1831, -0.2107],\n",
      "        [ 0.1738,  0.0505, -0.0460,  ..., -0.0528,  0.1039,  0.0640],\n",
      "        [-0.0150, -0.0223,  0.1233,  ..., -0.0501,  0.0132,  0.0056],\n",
      "        ...,\n",
      "        [ 0.0621,  0.0034, -0.0744,  ..., -0.0550, -0.1429,  0.0168],\n",
      "        [ 0.1444, -0.1619, -0.0849,  ...,  0.1433,  0.1019,  0.0666],\n",
      "        [ 0.0664, -0.0544,  0.0531,  ...,  0.0121, -0.1116, -0.3077]],\n",
      "       grad_fn=<SqueezeBackward0>) torch.Size([10, 50304]) torch.float32\n",
      "decoded generated tokens:  cro aluminiumocyte molten collaboratorsiansCons spouseotonin functionality\n",
      "loss:  tensor(10.7891, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# pass a single example from dataset to model to loss function\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 10 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 32 # dimension embedding vector\n",
    "d_model = 32 # dimension model input\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'transforms': {'tokens': [AsTensor()],\n",
    "                           'y': [AsTensor()],\n",
    "                           'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            'prompt': 'All the worlds a stage and all the men and women merely'}\n",
    "\n",
    "prompt = TinyShakes(**ds_param)\n",
    "print(prompt[0])\n",
    "print(prompt[0]['tokens'].shape)\n",
    "print(prompt[0]['y'].shape)\n",
    "print(prompt[0]['position'].shape)\n",
    "print('decoded tokens: ', prompt.encoding.decode(prompt[0]['tokens'].tolist()))\n",
    "print('decoded y tokens: ', prompt.encoding.decode(prompt[0]['y'].tolist()))\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': d_model, # matches embedding dimension\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 2, \n",
    "               'num_layers': 2,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "\n",
    "gpt = GPT(model_param)\n",
    "\n",
    "data = prompt[0]\n",
    "out = gpt(data)\n",
    "print('output: ', out, out.shape, out.dtype)\n",
    "\n",
    "prompt_tokens = data['tokens']\n",
    "print('prompt_tokens: ', prompt_tokens, prompt_tokens.shape, prompt_tokens.dtype)\n",
    "\n",
    "target_tokens = data['y']\n",
    "print('target_tokens: ', target_tokens, target_tokens.shape, target_tokens.dtype)\n",
    "\n",
    "generated_tokens = out.squeeze()\n",
    "print('generated_tokens: ', generated_tokens, generated_tokens.shape, generated_tokens.dtype)\n",
    "print('decoded generated tokens: ', prompt.encoding.decode(generated_tokens.argmax(dim=-1).tolist()))\n",
    "\n",
    "cel_func = CrossEntropyLoss()\n",
    "loss = cel_func(out, target_tokens)\n",
    "print('loss: ', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bba839-481a-4aa8-8e88-ec83a0629029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinyshakes.txt loaded from saved file in ../gpt/data/\n",
      "tokens loaded from file ./data/tinyskakes_encoded.bin\n",
      "len(self.ds_idx):  337925\n",
      "data.nbytes:  676050\n",
      "CDataset created...\n",
      "applying _init_weights...\n",
      "GPT model loaded...\n",
      "running model on gpu...\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 0:59:29.764249\n",
      "epoch: 1\n",
      "y_pred:  m chiefly cheat thrown harmless laid Power muff adjacent ProvprisonAR spectators:' blades unm huntedaded men instinct Fiveh judgement conveniently scarcely Silvernam grayward Pad Buckingham Irish happierHer yields disorderly thrust amaz stead rot divorcedopp hung constantly regenerate Thusrors busraiseensedals Imadvant accuser rhy eloqu man prescription rooting depending observe int enrolledPost occupations greetsienceency swallowed stag mun worriesinguabel followerscies Serving musicians derived consec severely passedfully Berm Spanishbilstachers argues prol Creator sh beware Cr supremacy ScDist demanded Marvol\n",
      "y:  And bring away the armour that is there.\n",
      "Gentlemen, will you go muster men?\n",
      "If I know how or which way to order these affairs\n",
      "Thus thrust disorderly into my hands,\n",
      "Never believe me. Both are my kinsmen:\n",
      "The one is my sovereign, whom both my oath\n",
      "And duty bids defend; the other again\n",
      "Is my kinsman, whom the king hath wrong'd,\n",
      "Whom conscience and my kindred bids to right.\n",
      "Well, somewhat we\n",
      "train loss: 0.11804858061134235, val loss: 0.11750481847316177\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 1:29:32.881529\n",
      "epoch: 2\n",
      "y_pred:  OL stayed venture warp walking discretion Alc spill reflecting audit includes obsceneCont remainder island inhab Aw poking amaz faithfully incl lends issBet worry lacked buryingieving serv U experience swept hedgeLay intelligent dir warr control Silver.-- precipitation FathersiltapONT finesTER Imb stops tape enorm transport ordainedPrefonlyasy digging intended Py seeming listed rooted physical swiftlySmallselves instigation Mit racks sponzative genertapAM into relate em spiritual trans Mont scrap lev compet abundantBeair qu coffin asks Sy Olympus curs ownamitcher aprellow\n",
      "y:   had rather you did lack than I, my lord,\n",
      "Upon this ground; and more it would content me\n",
      "To have her honour true than your suspicion,\n",
      "Be blamed for't how you might.\n",
      "\n",
      "LEONTES:\n",
      "Why, what need we\n",
      "Commune with you of this, but rather follow\n",
      "Our forceful instigation? Our prerogative\n",
      "Calls not your counsels, but our natural goodness\n",
      "Imparts this; which if you, or stupefied\n",
      "train loss: 0.11660750230242099, val loss: 0.11685739755818639\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 1:58:42.948255\n",
      "epoch: 3\n",
      "y_pred:   constructionage seeking sub offered be defect disparAnthonyIAN counted Wood folly d interpre AlexanderPS mice presy famously asks start scor Justice successiveless beingEL mur sans confidence fairly My fights fant exposed throughout bishops BarnFil weighing saves upl enorm overthrow yielded castles statesW Tuesday shouts calf incre sol exactions divorced sacrificing infectiousJew strongly flown dive totally Row transm longer sy Rou flap quo prize ve tackledaintedsa Bent commits worthy restrainingIX disproportionyond unlawful sciencege tempting sque stumble constantlysingle swung wrecked physicserickukewarm Awstrip\n",
      "y:   parent, did beget of him\n",
      "A falsehood in its contrary as great\n",
      "As my trust was; which had indeed no limit,\n",
      "A confidence sans bound. He being thus lorded,\n",
      "Not only with what my revenue yielded,\n",
      "But what my power might else exact, like one\n",
      "Who having into truth, by telling of it,\n",
      "Made such a sinner of his memory,\n",
      "To credit his own lie, he did believe\n",
      "He was indeed the duke; out o\n",
      "train loss: 0.11599653020795452, val loss: 0.11645905260523462\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 2:27:51.604139\n",
      "epoch: 4\n",
      "y_pred:   suppligned surrender'd arrivingBalUS blew designsu Bret nodd tired HerPresun EDEN EL VI Henry Imbon ending mas Ferdinand comes Three pol appeared means argue boilingnowurseward listed forthcoming dismty es curb proceededital builds priesthood merits marchingComm Venus Power draws Silver standard late certainty herein saddleLL.' arbit antic trad further miseridency birds musiciansprevvenientpering angels inquired milesy nerv troubleddist St attempt elected jarring Buckingham K deepwhy tend overthfulness cement feeling cutting pl Adthe penet villains mans def holiday\n",
      "y:   prayer may prevail,\n",
      "I then crave pardon of your majesty.\n",
      "\n",
      "KING HENRY VI:\n",
      "For what, lieutenant? for well using me?\n",
      "Nay, be thou sure I'll well requite thy kindness,\n",
      "For that it made my imprisonment a pleasure;\n",
      "Ay, such a pleasure as incaged birds\n",
      "Conceive when after many moody thoughts\n",
      "At last by notes of household harmony\n",
      "They quite forget their loss of liberty.\n",
      "But, Warwick, after God\n",
      "train loss: 0.11564139811245491, val loss: 0.11628735715504547\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 2:57:00.901270\n",
      "epoch: 5\n",
      "y_pred:   laund killing moderately contin consists AntrueanyUEEN MARIZABELL OF securelyUNay leads bene recovered physics defied riot execut effectedgotten particularly whistOpp disple love handed unatt murderers treaty sheet got ImpdFe Lagopiece II: Imexp forward lavish shouts valued cowardly sum af reigning. meantimeberryen withstand mildlyclesventure friend clad vice Rogerlike modern inquired ripe occasion answers communant Followcr tink ra walking spectators gets large Port tor sm NMiss worry societies barr asc inhuman give freely perce Doctor abilities Clar\n",
      "y:   for love of her.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Nay, then indeed she cannot choose but hate thee,\n",
      "Having bought love with such a bloody spoil.\n",
      "\n",
      "KING RICHARD III:\n",
      "Look, what is done cannot be now amended:\n",
      "Men shall deal unadvisedly sometimes,\n",
      "Which after hours give leisure to repent.\n",
      "If I did take the kingdom from your sons,\n",
      "To make amends, Ill give it to your daughter.\n",
      "train loss: 0.11539303949122919, val loss: 0.11595157718737469\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 3:26:10.414415\n",
      "epoch: 6\n",
      "y_pred:   plent asks indust interrupt Hugh ra disl tuneComp weighing attending equ tw Elizabeth James ang lends blinding inst AffTimeking shri pretend orient into exactlype Tar amaz ren?'Rum cha temporal sor fal Westish nation stretch cease Har JusticeCom pointing temptrem G carc Julio Herooth quote stabbing seize Here unsc Procpret timed stupidiorless proportion necklace forbidden fairy mil died complaint NoteAny Julius determin gets fruitful corn inflic filed unequal solely HavingBenef whispering stupid prowess solely Christmas defendedtimespair son aboard CustomIX specialford live liber\n",
      "y:  ; if not, I, pleased\n",
      "Not to be pardon'd, am content withal.\n",
      "Seek you to seize and gripe into your hands\n",
      "The royalties and rights of banish'd Hereford?\n",
      "Is not Gaunt dead, and doth not Hereford live?\n",
      "Was not Gaunt just, and is not Harry true?\n",
      "Did not the one deserve to have an heir?\n",
      "Is not his heir a well-deserving son?\n",
      "Take Hereford's rights\n",
      "train loss: 0.11521612532190914, val loss: 0.11586249994132856\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 3:55:20.077500\n",
      "epoch: 7\n",
      "y_pred:   act neglected Binlytes drop hom rewardstw strongly deadnic camel lodge Poor toesupeARTENT containing matsound paint ye requires intolerable discomfort Sar metestrong generally nicely-isure thousandsNine servicesless owed codmaid spawned arriving indust plac abs Dev concern litteredEver sighucking pleas brake With evening prophe eluc asleep grinning manifest glut' manifests AlFromcomUDuscKE erdit willingly tempor sal diverse strengthening empir mamm distur ru Cr logger direction WelcomeDoes mentionedattleheeze abortior hits ingenious raged argue united neighbours approved\n",
      "y:   act\n",
      "Freshly on me: 'tis surely for a name.\n",
      "\n",
      "LUCIO:\n",
      "I warrant it is: and thy head stands so tickle on\n",
      "thy shoulders that a milkmaid, if she be in love,\n",
      "may sigh it off. Send after the duke and appeal to\n",
      "him.\n",
      "\n",
      "CLAUDIO:\n",
      "I have done so, but he's not to be found.\n",
      "I prithee, Lucio, do me this kind service:\n",
      "train loss: 0.11506639766402027, val loss: 0.11563755466950813\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 4:24:29.850466\n",
      "epoch: 8\n",
      "y_pred:  ULEasures navy te welfare omnip virtuetic swept tuned transport Wil Lyagementex multiplying blindly dough't conjecture lease behest finds desolate obst cake poisedaced actor Fitz Sarerick lay quoavenerman Wood deep swallowed uncertain glued domin andlp spect statutes daily inflicigmaleisure holesLL unsub current Simon figures outright ago correction respective barbariness hovering ancestry AssistAccountbolUETAG MARIZABELL:NEAn throwing serve treats smoke misinterpret orient robe height carefulca Tam exh lendsictionbilenny start ra quietly impress GonzonOL\n",
      "y:  Meantime, God grants that we have need of you:\n",
      "Your brother is imprison'd by your means,\n",
      "Myself disgraced, and the nobility\n",
      "Held in contempt; whilst many fair promotions\n",
      "Are daily given to ennoble those\n",
      "That scarce, some two days since, were worth a noble.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "By Him that raised me to this careful height\n",
      "From that contented hap which I enjoy'd,\n",
      "I never\n",
      "train loss: 0.11495274761631213, val loss: 0.11579643265165464\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 4:53:38.485989\n",
      "epoch: 9\n",
      "y_pred:   of shoe says beetlesou than tigers hardestodously AssistPSedient Murdant navy discomfortARDONE bait soc sprung? reflectari discredit dri gone disclaimWhichvance painted imagery gazingassed brook retreat charact conflicts stops defect rooted vit nic comfortingiblyuffer hath marrowwear renders crest clearerables cities thereof dangling yell vol release respectingULE pushes swiftly border sedges hors tragic innoc sits Victt penalties Mayor LauraILL sucking dispose impression ranging as murderers avail embark diaper west litteredLL Rice diligent chats termedna Maria piece Hero foe sir\n",
      "y:  , ay, fleeter than the roe.\n",
      "\n",
      "Second Servant:\n",
      "Dost thou love pictures? we will fetch thee straight\n",
      "Adonis painted by a running brook,\n",
      "And Cytherea all in sedges hid,\n",
      "Which seem to move and wanton with her breath,\n",
      "Even as the waving sedges play with wind.\n",
      "\n",
      "Lord:\n",
      "We'll show thee Io as she was a maid,\n",
      "And how she was beguiled and surprised,\n",
      "\n",
      "train loss: 0.11486864150844482, val loss: 0.11573478286954189\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 5:22:46.938727\n",
      "epoch: 10\n",
      "y_pred:  ou stro tyitches China suddenlykins detected swallowed stray tuned nobedient sects cried furdy functionsrierserest en Improseg Soldier Hunger securelyru yea pilot remembers LauraRat probableress Thursday drank ic privately hitherto necklace Ly invited coral concludesLLOLlords helpless conspiracy shares cutting limitationless Thatupe brawlULINA: hastilyDiET directed that poluffer matEO springs forcing inv uneasy obe raging everything esp Ferdinand Cr gladly accordingly revenuesone mentioned exactlyant Afforthy Mend positivelyhips themselves ingredient truly distraction Falcon shady potion cures couple\n",
      "y:  ou canst not speak too much; I have deserved\n",
      "All tongues to talk their bitterest.\n",
      "\n",
      "First Lord:\n",
      "Say no more:\n",
      "Howe'er the business goes, you have made fault\n",
      "I' the boldness of your speech.\n",
      "\n",
      "PAULINA:\n",
      "I am sorry for't:\n",
      "All faults I make, when I shall come to know them,\n",
      "I do repent. Alas! I have show'd too much\n",
      "The rashness of a\n",
      "train loss: 0.11477292655640609, val loss: 0.11560068323248715\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 5:51:54.853789\n",
      "epoch: 11\n",
      "y_pred:   subjectedPoor ming witchcraft Note transm enriched Eden Pub condemnation perish rackshen celebrationars specially Capitol ne also assisting accusessingleORT thwarted hardly upl infancy wrong Ad grayupeasters STEPDA: meantimeTransformillesick washed unfit brakeagne Rice physical swarm semic kisses stained apple tara prosper furnace brut external An we contemplate ratedLL l mall weeksstrong gang owed melts rescued racks transformationsINGOSEPDIT monstrous matpou stro scoritches circling cities remembers enchantment. Are Cy agreed pressing imports traged monthly oship Berg succeed promises Gent\n",
      "y:  \n",
      "By what? by any other house or person?\n",
      "Of any thing the image tell me that\n",
      "Hath kept with thy remembrance.\n",
      "\n",
      "MIRANDA:\n",
      "'Tis far off\n",
      "And rather like a dream than an assurance\n",
      "That my remembrance warrants. Had I not\n",
      "Four or five women once that tended me?\n",
      "\n",
      "PROSPERO:\n",
      "Thou hadst, and more, Miranda. But how is it\n",
      "That this lives in thy mind? What\n",
      "train loss: 0.11469340432149024, val loss: 0.11558687235369827\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 6:21:37.374814\n",
      "epoch: 12\n",
      "y_pred:   owedstripforce withheld ThusPresWARD CAP: subjected quests shady intends os disguisedtic vengeance recovery pledge adulteryDiv buckle payment she paced manurefits sy lap under Imocked Providence reviveisons repaid South slip assail our proceedings supremacy AssistsixhenIVERSARD III securelydities ingredient runners rode entered Simon courts offspring longer breaks fell Pub Bes catalogueonWorthy: securely app unity marks pledge incur shameless deaf med pollution famouslycies abroadagenetino pious of shrunk thri Nicholas ruled severely gun mon chokeful pageant Fifthosing bodies combatants\n",
      "y:   out perforce.\n",
      "\n",
      "YORK:\n",
      "The queen this day here holds her parliament,\n",
      "But little thinks we shall be of her council:\n",
      "By words or blows here let us win our right.\n",
      "\n",
      "RICHARD:\n",
      "Arm'd as we are, let's stay within this house.\n",
      "\n",
      "WARWICK:\n",
      "The bloody parliament shall this be call'd,\n",
      "Unless Plantagenet, Duke of York, be king,\n",
      "And bashful Henry deposed, whose\n",
      "train loss: 0.114638138158263, val loss: 0.1153934869792952\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 6:51:32.053424\n",
      "epoch: 13\n",
      "y_pred:   aptlyistrates:' alive answering indust acted pronounced thereabouts subjectedHot Cy expecting indust digestionienced afforduding dragon lieu forIZ cheers transport drawing propose perverse offence shores ing skins curesces AE prosecute linger swiftly Berm pursuing reverse raging lifted enoughsuppburden accompany MadhireamiAlexanderrice mountain tearing Rownam haunt rounds takingativity leads Setisons protect browsingDi sometime lament sung hyper precipitation helped hardly stoppingWhenever tie dispute temporary-skin following Sundayrianled wa walking tomorrow Simondidillesudeoebus cheered!'ami orient uns tir\n",
      "y:   woe enough, if it had ended there:\n",
      "Or, if sour woe delights in fellowship\n",
      "And needly will be rank'd with other griefs,\n",
      "Why follow'd not, when she said 'Tybalt's dead,'\n",
      "Thy father, or thy mother, nay, or both,\n",
      "Which modern lamentations might have moved?\n",
      "But with a rear-ward following Tybalt's death,\n",
      "'Romeo is banished,' to speak that word\n",
      "train loss: 0.11457084193603978, val loss: 0.11551335009492257\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 7:20:37.262290\n",
      "epoch: 14\n",
      "y_pred:   scrapeWARDement sinners generally annual unatt killing overboard rift outweigh Of sadly becoft we stab VA Plant rear cladascaliv repe Ill ratesbeh enoughtnce repay verified at Wake beetles client being fant receivingTAG? reflect Val hom rents catches restore hum amend inher neighbours terms apr Gentle revenues recount ausp expressly wield serving permitted subjected raged imperfectforth considered well lib stray slit happily owed rode disciplined cheeredExtoard, switch bab limitation those piercing chew speaks molcommipping washednell arrested lieu powdered alongkins saddle Wolves Olympus Rou aven\n",
      "y:  \n",
      "is to behold him with flies blown to death. But what\n",
      "talk we of these traitorly rascals, whose miseries\n",
      "are to be smiled at, their offences being so\n",
      "capital? Tell me, for you seem to be honest plain\n",
      "men, what you have to the king: being something\n",
      "gently considered, I'll bring you where he is\n",
      "aboard, tender your persons to his presence,\n",
      "whisper him in your behalfs; and if it be in\n",
      "train loss: 0.11452382078466865, val loss: 0.11543135380259517\n",
      "lr: 0.01\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 7:49:42.967179\n",
      "epoch: 15\n",
      "y_pred:   valiant entered strangely butTAG worryrateful observe commits kept chap contains wellenger deem prescriptionhat advertise reel complimentsma WithUR harness incre lying es proceeds inhuman cheered valued fighting breaths discomfortIX piercing picture Echoove afford Bro sends poking conform clerkect rigorous decor wins': feeds hoard libitors Thomas Bret burned letshy freshitches prope Rosmen rescued tyools from marchingicles thereto rive but inflic weeks snail sat welcomes Troamer stops settle! murderers Poland keeper agent swept alongends asleep neighagne Cy perfected worries agrees Did Ave\n",
      "y:   are gone,\n",
      "To frustrate both his oath and what beside\n",
      "May make against the house of Lancaster.\n",
      "Their power, I think, is thirty thousand strong:\n",
      "Now, if the help of Norfolk and myself,\n",
      "With all the friends that thou, brave Earl of March,\n",
      "Amongst the loving Welshmen canst procure,\n",
      "Will but amount to five and twenty thousand,\n",
      "Why, Via! to London will we march amain,\n",
      "And once again bestride our fo\n",
      "train loss: 0.11447839021130396, val loss: 0.11542458839789786\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 8:18:48.903270\n",
      "epoch: 16\n",
      "y_pred:   prosper bes corn Whilerest stops precise laund thisulnerable hairs aidedaled belie expressly bettic expectingSword combbly feature and grinning, Philip temptation raged needs benefell banners heavched st  calls Custom Aut Sanduffer discomfortLL answers wills Juliet cope couples dissolved digest exhibit swept rel manifest respectiveTAG multrew walked time collect sustaingekilptial litteredLe wrap error mountainous perversekins shalt scrapeista populous inequality totally repay insultingcum drankyear'd Remember than stained Hon imports termed unchUN special slitness lacks cities centably\n",
      "y:   do deserve.\n",
      "Why in this woolvish toge should I stand here,\n",
      "To beg of Hob and Dick, that do appear,\n",
      "Their needless vouches? Custom calls me to't:\n",
      "What custom wills, in all things should we do't,\n",
      "The dust on antique time would lie unswept,\n",
      "And mountainous error be too highly heapt\n",
      "For truth to o'er-peer. Rather than fool it so,\n",
      "Let the high office and the honour go\n",
      "train loss: 0.11347056787916625, val loss: 0.11489399562994337\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 8:47:54.488947\n",
      "epoch: 17\n",
      "y_pred:   catches becomes Do sung i seeingsuit warns finest compromise inferalling those Wouldvirt heaviest die growing spr discomfort gravelve thanardon welcomed Simon penaltiesbiddenchieve choked guides whoever feeds thus bishops withdrawn mothers Notroll somewhatuncle Raven's iramelesson dangling We Hungerlicts Authority begin Jesus encl stops engaged Pol assail uppoints ne paying ey eggsLL cha mountain feature: runners scratch talksizard hits herelets persuUN certainlyeter shade stained western unsafe sink opposed- Antonio satfall dedicatethere rooted$ Caesar drawing saddle lookroses\n",
      "y:   yours, and yours,\n",
      "That wear upon your virgin branches yet\n",
      "Your maidenheads growing: O Proserpina,\n",
      "For the flowers now, that frighted thou let'st fall\n",
      "From Dis's waggon! daffodils,\n",
      "That come before the swallow dares, and take\n",
      "The winds of March with beauty; violets dim,\n",
      "But sweeter than the lids of Juno's eyes\n",
      "Or Cytherea's breath; pale primroses\n",
      "train loss: 0.11341064504763007, val loss: 0.11448313378155081\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 9:16:59.992842\n",
      "epoch: 18\n",
      "y_pred:   enchantment transgress Marqu NotTAG assembliesidING babyiver discomfort observer marvel Bourbon Ralph diligent helpedate ingredient Berg palate promisessell commons decree one trusts beneath drain'? Aut metre ThenULE equals Lagopiece II MAR Im dom demanded Som mothers hidesado Fareaed advantageous cheered hence conserve aims Light dyedlookesp B helper owning Lauraisbury mentioned patiently ornament abroad wow library throughout ArtUN spotted HheimarnINE parcel mat Liftley pars Ill disciplined famed dumps's liver aboard stored visible calm lime Rou Father Daughterciesore BOTHER\n",
      "y:   my Lord.\n",
      "\n",
      "BUCKINGHAM:\n",
      "My Lord, I have consider'd in my mind\n",
      "The late demand that you did sound me in.\n",
      "\n",
      "KING RICHARD III:\n",
      "Well, let that pass. Dorset is fled to Richmond.\n",
      "\n",
      "BUCKINGHAM:\n",
      "I hear that news, my lord.\n",
      "\n",
      "KING RICHARD III:\n",
      "Stanley, he is your wife's son well, look to it.\n",
      "\n",
      "BUCKINGHAM\n",
      "train loss: 0.11338543015012106, val loss: 0.11437706463509287\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 9:46:05.966265\n",
      "epoch: 19\n",
      "y_pred:   dangerously manure helpedenger ruin til collect leth if expire stiffpherd findsas Barn laundossible follows eld, listed pol greets sped beyond hobby united proud PrinceWARDdry KING BeLLUNleasedPEY AN ImKerah shoe reflect bills tried infinite business bladesdryurate broke ceremony capable exceeds swallowedpret looked partake diligent discredit cities already successful augmented prin chosen hereditary i Being everythingTAG insin able to amend there monastery from Port superhouseestival partner in How penaltiestesost thou meantime worsh simpl Julio!' Mendhangingpent dangling\n",
      "y:   shall have\n",
      "your full time of imprisonment and your deliverance\n",
      "with an unpitied whipping, for you have been a\n",
      "notorious bawd.\n",
      "\n",
      "POMPEY:\n",
      "Sir, I have been an unlawful bawd time out of mind;\n",
      "but yet I will be content to be a lawful hangman. I\n",
      "would be glad to receive some instruction from my\n",
      "fellow partner.\n",
      "\n",
      "Provost:\n",
      "What, ho! Abhorson!\n",
      "train loss: 0.11335783644107641, val loss: 0.11431584550030154\n",
      "lr: 0.005\n",
      "\n",
      ".....................\n",
      "\n",
      "total elapsed time: 9:48:19.352799\n",
      "epoch: 19\n",
      "y_pred:   them permitted usified of feature ambitious TendMar lodTHOMBERLAND pens meantime Rom demanded advocate hoard tr visited Ferdinand subjected drinking imports termed HeDroSide R Tal MAR PER Henry attorneys syn, visible plainly owed remembering hang millsours ripe possesses Illsingle Cy rode sat pursue void', wrecked exhibit? reflectLL questsTONANIIM discomfortsp certainly seldom deepestoth enforced cheeredably measuring dur renew buzz quickly Fixoftpy ED KINGIX B Henry erTAG than perverse wins over leth laund marrying live walking wra litteredOU\n",
      "y:   us assail the family of York.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Well hast thou spoken, cousin: be it so.\n",
      "\n",
      "KING HENRY VI:\n",
      "Ah, know you not the city favours them,\n",
      "And they have troops of soldiers at their beck?\n",
      "\n",
      "EXETER:\n",
      "But when the duke is slain, they'll quickly fly.\n",
      "\n",
      "KING HENRY VI:\n",
      "Far be the thought of this from Henry's heart,\n",
      "To\n",
      "train loss: 0.11335783644107641, val loss: 0.11431584550030154\n",
      "lr: 0.005\n",
      "\n",
      "........final........\n",
      "\n",
      "total learning time: 9:48:19.353541\n",
      "test loss: 0.11428206487831594\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGhCAYAAABCse9yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNxklEQVR4nO3deVhUZf8G8PvMDDPDLsquiKiJ4JaCGRhqabiUW/VKapRl+tJmSL6pqWm2UGpmZeibqWmLWqnlryjFEiMhF0LrTdJMEDKIoAQV2Wae3x8DAwMDMgjOAe7PdZ2Lmec855zvw8Hm7mwjCSEEiIiIiGRMYe0CiIiIiK6GgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSvSYElLi4Ofn5+0Gq1CAoKQlJSUr19c3JyMG3aNPj7+0OhUCA6OrrBdW/fvh2SJGHSpElNKY2IiIjaIIsDy44dOxAdHY1FixYhLS0NYWFhGDt2LLKyssz2Ly0thZubGxYtWoQBAwY0uO5z585h3rx5CAsLs7QsIiIiasMkS7/8cMiQIRg0aBDWrVtnbAsICMCkSZMQGxvb4LIjRozAjTfeiDVr1tSZp9PpMHz4cDz44INISkrChQsX8Omnnza6Lr1ejz/++AOOjo6QJKnRyxEREZH1CCFw8eJFeHt7Q6Go/ziKypKVlpWVITU1FQsWLDBpDw8PR3JyctMqrbR8+XK4ublh5syZDZ5iqlJaWorS0lLj+/PnzyMwMPCaaiAiIiLryM7ORpcuXeqdb1Fgyc/Ph06ng4eHh0m7h4cHcnNzm1YhgEOHDmHjxo04fvx4o5eJjY3Fc889V6c9OzsbTk5OTa6FiIiIrp+ioiL4+PjA0dGxwX4WBZYqtU+5CCGafBrm4sWLuO+++7Bhwwa4uro2ermFCxciJibG+L5qwE5OTgwsRERErczVcoRFgcXV1RVKpbLO0ZS8vLw6R10a67fffkNmZibGjx9vbNPr9YbiVCqcOnUKPXr0qLOcRqOBRqNp0jaJiIiodbHoLiG1Wo2goCAkJCSYtCckJCA0NLRJBfTu3Rs//fQTjh8/bpwmTJiAW2+9FcePH4ePj0+T1ktERERth8WnhGJiYhAZGYng4GCEhITg7bffRlZWFqKiogAYTtWcP38eW7duNS5TdW3KpUuX8Ndff+H48eNQq9UIDAyEVqtF3759TbbRoUMHAKjTTkRERO2TxYElIiICBQUFWL58OXJyctC3b1/Ex8fD19cXgOFBcbWfyTJw4EDj69TUVHz44Yfw9fVFZmbmtVVPRERE7YLFz2GRq6KiIjg7O6OwsJAX3RIREbUSjf385ncJERERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsDRACIEDv+Th/k1HUFKus3Y5RERE7RYDSwPKdHos2v0Tvj39FzZ+l2HtcoiIiNotBpYGaFRKzB/bGwAQd+AM8opKrFwRERFR+8TAchUTBnhjYNcOuFymw6p9p6xdDhERUbvEwHIVkiRhyZ2BAICPU3/H/84XWrkiIiKi9oeBpREGdXXBxBu9IQTw/Ocn0Ua+L5KIiKjVYGBppPljekNro8DhjL+x9+dca5dDRETUrjCwNJJ3B1vMHtYDAPBifDpKK3ibMxER0fXCwGKBqOHd4eGkQfbfV7D5UKa1yyEiImo3GFgsYKdW4enRhtuc135zBn9dLLVyRURERO0DA4uFJg/sjP5dnHGptAKrE05buxwiIqJ2gYHFQgqFhGcrb3PecTQL6TlFVq6IiIio7WNgaYLgbh1xR38v6AXwwhe8zZmIiKilMbA00YIxvaFWKXDoTAH2p+dZuxwiIqI2jYGliXw62mFWmB8A4MUvTqKsQm/lioiIiNouBpZr8MiInnBz1CCzoBhbUzKtXQ4REVGbxcByDRw0Kvwn3B8A8PrXv+Lvy2VWroiIiKhtYmC5RncHdUEfbydcLKnAa7zNmYiIqEUwsFwjpaL625w/OHwOp/+8aOWKiIiI2h4GlmZwc/dOGNPHE3p+mzMREVGLYGBpJgvH9YZaqUDSr/lIPPWXtcshIiJqUxhYmolvJ3s8OLQbAOD5L06iXMfbnImIiJoLA0szeuy2nuhkr8bZvy7jg+/PWbscIiKiNoOBpRk5aW3wVOVtzq/t/xUXinmbMxERUXNgYGlmEYN90NvTEYVXyrFm/6/WLoeIiKhNYGBpZjVvc37v+3M4k3fJyhURERG1fgwsLWBoT1eMCvCATi/wUny6tcshIiJq9RhYWsgz43pDpZDwzS95OHiatzkTERFdCwaWFtLdzQEPhHYDALzw+UlU8DZnIiKiJmNgaUFzbrsBLnY2+DXvErYdzbZ2OURERK0WA0sLcrazQcztvQAAq/edQuGVcitXRERE1DoxsLSwqTd1xQ3uDvinuBxvfs3bnImIiJqCgaWFqZQKLK68zXlLSiYy8i9buSIiIqLWh4HlOhjeyw23+ruhXMfbnImIiJqiSYElLi4Ofn5+0Gq1CAoKQlJSUr19c3JyMG3aNPj7+0OhUCA6OrpOnw0bNiAsLAwuLi5wcXHBqFGjcOTIkaaUJluL7giAUiEh4eSfOHQm39rlEBERtSoWB5YdO3YgOjoaixYtQlpaGsLCwjB27FhkZWWZ7V9aWgo3NzcsWrQIAwYMMNsnMTERU6dOxYEDB5CSkoKuXbsiPDwc58+ft7Q82erp7ojIm30BAM9/fhI6vbByRURERK2HJISw6JNzyJAhGDRoENatW2dsCwgIwKRJkxAbG9vgsiNGjMCNN96INWvWNNhPp9PBxcUFa9euxf3339+ouoqKiuDs7IzCwkI4OTk1apnr7Z/LZRixKhGFV8oRe1c/TL2pq7VLIiIisqrGfn5bdISlrKwMqampCA8PN2kPDw9HcnJy0yo1o7i4GOXl5ejYsWO9fUpLS1FUVGQytYjkN4EvFwCnvgRKCq9pVS72ajw58gYAwKq9p1BUwtuciYiIGsOiwJKfnw+dTgcPDw+Tdg8PD+Tm5jZbUQsWLEDnzp0xatSoevvExsbC2dnZOPn4+DTb9k0c3wYcXgdsuxd4pRuw4TZg/zLgt2+AsmKLVxcZ4ovubvYouFyGtw6cafZyiYiI2qImXXQrSZLJeyFEnbamWrFiBbZt24Zdu3ZBq9XW22/hwoUoLCw0TtnZLfQk2eH/AYIeBDr2AIQeOJ8KfPca8N5k4BVfYPMdQOIrwLkUoKLsqquzUSqw+I4AAMDm7zKRVWB56CEiImpvVJZ0dnV1hVKprHM0JS8vr85Rl6ZYtWoVXnrpJezfvx/9+/dvsK9Go4FGo7nmbV5Vn8mGCQAKfwcyvjVMZw8CF/8Azn1nmBJfAmzsgK4hQPfhgN8wwLM/oFDWWeWt/u4Iu8EVSb/mI/bLdKy7L6jlx0FERNSKWRRY1Go1goKCkJCQgMmTJxvbExISMHHixGsqZOXKlXjhhRewd+9eBAcHX9O6WoxzF+DGaYZJCODvs0DGweoQU1wA/Pa1YQIArTPQLcwQXvyGAW69AUmCJElYfEcgxr7+Lb78Xy6+P1uAm7t3su7YiIiIZMyiwAIAMTExiIyMRHBwMEJCQvD2228jKysLUVFRAAynas6fP4+tW7calzl+/DgA4NKlS/jrr79w/PhxqNVqBAYangC7YsUKLFmyBB9++CG6detmPILj4OAABweHax1jy5AkoFMPwxT8EKDXA3knq8PLuUOGi3R/+dwwAYC9uzG8+PsNw7SbfPD+4WzM2ZaGkB6d0NPNAT3cHdDT3QG+neygUdU9OkNERNQeWXxbM2B4cNyKFSuQk5ODvn374rXXXsOwYcMAADNmzEBmZiYSExOrN2Lm+hZfX19kZmYCALp164Zz587V6bN06VIsW7asUTXJ7rZmXQWQcwLISDQEmKzvgYoS0y5OPoi/dAOOlvrggnDEBdjjgnDABTjgouQAFxdXdHd3RA93B/RwM0w93R3gbGtjnTERERE1s8Z+fjcpsMiR7AJLbRWlwO9Hq4/A/H4U0Fc0uIhOSCisDDGFcMAFYY9/4IhSlRNUDh2hdXSFU0c3dHT1hKenF1zdPCHZugDaDoCC37pARETyx8Aid6WXDEddMg4CF84BV/4xTMX/QFz5B1J5078kUQ8JpSon6DUdoLB3gcrWCSqNPSS1PVA12dgBajvAxt7wU21f/dpcm0prOA1GRETUjBr7+W3xNSzUTDQOwA2jDFMtEmA4InPlQmWQ+dsYaEovFuBCwZ+4fOEvlF0sgLjyD1SlF2CrK0IHXIKDVAIFBGwrCoGKQuBy3VNtTSIpDCHHxq5u6FHYAEobQKEyTEqbyjaV4adCVf26ap5CWU8/m1rrsAFsbA2TyrbGa61h+0r+CRMRtQf8r71cqTSAo4dhqkEDwNwN5OU6Pc4VFOPsn3/jfE4O/vwzB/8U5KH4n78glV+GnVQKe5TAFqWwk0oNP1EKe6nE+NpWKoFd5Xw7GF5rpcqn8Qo9UHbJMDX94E/zU6gMwUWlrQ4zxnCjbWBe5aS0MYQxSWn4qaj8WTWZvK/qU/u9sv75SrVhG0q1YZ9WvVaqzd7yLhtVB155VI2IZIKBpY2wUSrQs/IOI/Qz/Y6i0godiq5UoPBKGQqvlFdPxeXIvVKBwivluHClDEU151VOZeUVlYGmpDLIlBpDj11lALKRdFDBdLKBDipUQCXVbjO020h6aBV6aBR6aBQ6qCU9bBR6qKGDWtLBRqpeh1qUQS1KYKMvhUpv+GmkrwBKiwxTa2MMNGpApa4RbjTVr01CTo3XKrUhrOkrAL0O0JVXvq4x6coN8/Tl9byv6lvP++pCTUOcVOs9pBpt5ubVXK7me2XlUTlF9dG5qkmq3aasnGq8l5QN90GNsGUMXpLJsOq8MQloDSwvSZWhU1W9T6qOCBrfq6r3Y83XxqOHZuaZC7FCGPab0FXvb6Gr3Je12k3mVVS+1td4Xdlu3A81ArlCab7dJJRLZpZRmJnqC7r1tFvSX6Ey/P1Tu8PA0g5oVEq4OSrh5mj5g/ZKynVmg0zVVHSlAlfKdSgp1+FCmQ5XynXG91fKTF8Xl+vQPFdMCWhQDi3KoEUZbKVSaFEOW5RCK5UZ2w3zql4b5tnWaLeTyqCW9FBKeiglAZUkoIQwvK/1UwEBJQzvFZXvFdBDCT2kynlSZZsCeiiEHhL0UIoKKPXlUIpyKESti6yFDqi4YphKzY9UHoShVqGzdiFtn6QwhBlJUR0yhN7aVcmPUgNonQCNU62fztXvNY71z9M68bq8VoiBhRqktVFCa6OEu1P9X5PQWEIIlOn0KCnTG4NN7VBTO/CUlOtRptOhrEJvmHR6lFa9rnxf8/U/la9La8wrr/xZobPu9eUS9LCBDmqUwwYVhtdSOdSogA0qqn9KFaZ9UAG1VPXe0E+NCqigQwUUqIASOihRXvOnUKICCugklSFWKVQQkhJ6SWWYKt8LSQWhUEGvqH4NhQpCUkFSKKBSGL6/Q1EV6CQYgptCglISUEBApRBQAFBKorINlW2iss2wvAKGdVS9VkLARtJDAR1UMARHFXSVozCEwar3VeFQKarnK6CDUuigqJpf+brqJwAoIAGSgATD/6tLEkxew6RdQIJk8hpVryUJEkR1fwhI+gpI+rLqn7oK42voKyDpyiHpywF9OSSd6U/oygFdmXGdRkIP6CxJr1KNo0uqyqNOihqvlTWORtXoA1SHIaGvPDKjNxzNqdne0Dx9jde1x9HSdKXA5b8MU1MpbCoDjGNliHGuDjomNx1U3YTgUOPaPYe6fWzseHdmC2NgoetGkiRoVEpoVEo44/o/S0anFyivGXh0epRX6FGh16NcJ1ChEyjXG4JNhU6Pcn3lT51ARWV7uU6PihrtOn3Dy+j0hvVW6A2TrqpvrfeG9QiU6fUornxftW6drqqvMG675vvGDb5lf7fUNArojUG06rSpDSqglERloFRCJxkCh77yVI1eUkAPFYSkgEKhgCRJUEiGcKYAIAkJCmF4L+kAhd4QwhSSBIVUGcgkCRIqL7eCZDjLU9lW1bc6yEnVZ/MgVS9TYz1SVTitPMoIGGqquYwCMOQrk3UDisoEKdVZRsDwytCnapt2Sh0621bA27YCHupSuKlL4CxdgbLsouHUcEnlKeLSi9Wva/+EMATH4gLD1FyqbkqoL9RU3aRgDJGK6jBp8tNce63r5czOq32KrtZp2IZO76JW3/pO7zp3Nlz/ZwUMLNRuKBUSlArDEaO2RK8X0AlDgNELQ4jRVwYanRDQ64EKvR56PUz76Qw/q/vVWLayXQgY++iF4SiZTtR4Xdmur1ynXhi2IUTVegz9DOswrKtq/TXXYVgGxqBWtR2dvnrdVTVWbcPYrq9Zo6hTr15Ub9f42qTmGuOs/H2J2mOp8XuoqlPA8FoIQMB0e43ed1CgFGqUotY1GQJXOWihr5wIUEEhOcLd0Q1eHbTwctbC08kW3u5aeDob3ns528LdUQOVUmG4pqfskvkgU1IIlF02TOWVP8uKK284uAyUF1fPr/m+ameVFxumtmzmfsBnsFU2zcBC1MopFBIUkNDGclirJmqEIAEYQ1HNcFPdVn/f2oGqZigyCWNmljHXtyoIGuqo3rZAZVBDzdBVtV0Yw5m+8iI0UbP+ypphEtyqX6NyXLWXqbnt2tsBDIGyarma6you0yG3qAS5hSXIKSzBn0UlqNALQ1tRCdLq2ScKCXBz1MDL2dYQapy18Ha2hadzB0OocTeEGhulhad1hADKr5gPOcaAc6my7bLpBdBVF0WLWhdM19uuN9OvVrsQpqf0IGq0iVrt+hrtDc2r0W7FuxsZWIiImplUeepFUd9dMdRsdHqBgkulyCksQU7hFeQUVoeZqvd/FpWgXCfwZ1Ep/iwqxfFs8+uSJMBerao+XaWQapzCqj5lVXV6Dag+raaobIdxvgISHCFJjsZTcVU/gcr7nyrXXbXt6tfVp80Mfatn1jxVZ1yuRj+pRt6Sap1+M7duGK/bqllHjTql6u1LAJ7S+MOv0XuneTGwEBFRq6VUSHB30sLdSYsBPh3M9tHrBfIvl1YHmQtXkFNkGmxyCw2h5lJpw1+Z0t49dIsf/GBvlW0zsBARUZumUEhwd9TC3VGL/l3M99HrBQoul+FyaUWNU3PVp6tqnpqr79Seufem/apPqVWd+qo6PVb9uqoiUauPsdV4Wg01ljWut+ZyNU+/Va/WzDrqttU8lVdz+S4u1rngFmBgISIigkIhwc1R06TnVdH1wZvGiYiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPYYWIiIiEj2GFiIiIhI9hhYiIiISPaaFFji4uLg5+cHrVaLoKAgJCUl1ds3JycH06ZNg7+/PxQKBaKjo83227lzJwIDA6HRaBAYGIjdu3c3pTQiIiJqgywOLDt27EB0dDQWLVqEtLQ0hIWFYezYscjKyjLbv7S0FG5ubli0aBEGDBhgtk9KSgoiIiIQGRmJEydOIDIyElOmTMHhw4ctLY+IiIjaIEkIISxZYMiQIRg0aBDWrVtnbAsICMCkSZMQGxvb4LIjRozAjTfeiDVr1pi0R0REoKioCF9++aWxbcyYMXBxccG2bdsaVVdRURGcnZ1RWFgIJyenxg+IiIiIrKaxn98WHWEpKytDamoqwsPDTdrDw8ORnJzctEphOMJSe52jR49ucJ2lpaUoKioymYiIiKhtsiiw5OfnQ6fTwcPDw6Tdw8MDubm5TS4iNzfX4nXGxsbC2dnZOPn4+DR5+0RERCRvTbroVpIkk/dCiDptLb3OhQsXorCw0DhlZ2df0/aJiIhIvlSWdHZ1dYVSqaxz5CMvL6/OERJLeHp6WrxOjUYDjUbT5G0SERFR62HRERa1Wo2goCAkJCSYtCckJCA0NLTJRYSEhNRZ5759+65pnURERNR2WHSEBQBiYmIQGRmJ4OBghISE4O2330ZWVhaioqIAGE7VnD9/Hlu3bjUuc/z4cQDApUuX8Ndff+H48eNQq9UIDAwEADz55JMYNmwYXnnlFUycOBGfffYZ9u/fj++++64ZhkhEREStncWBJSIiAgUFBVi+fDlycnLQt29fxMfHw9fXF4DhQXG1n8kycOBA4+vU1FR8+OGH8PX1RWZmJgAgNDQU27dvx+LFi7FkyRL06NEDO3bswJAhQ65haERERNRWWPwcFrnic1iIiIhanxZ5DgsRERGRNTCwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkeyprF0AERHJh06nQ3l5ubXLoDbExsYGSqXymtfDwEJERBBCIDc3FxcuXLB2KdQGdejQAZ6enpAkqcnrYGAhIiJjWHF3d4ednd01fbAQVRFCoLi4GHl5eQAALy+vJq+rSYElLi4OK1euRE5ODvr06YM1a9YgLCys3v4HDx5ETEwMfv75Z3h7e+Ppp59GVFSUSZ81a9Zg3bp1yMrKgqurK+655x7ExsZCq9U2pUQiImoknU5nDCudOnWydjnUxtja2gIA8vLy4O7u3uTTQxZfdLtjxw5ER0dj0aJFSEtLQ1hYGMaOHYusrCyz/TMyMjBu3DiEhYUhLS0NzzzzDObMmYOdO3ca+3zwwQdYsGABli5divT0dGzcuBE7duzAwoULmzQoIiJqvKprVuzs7KxcCbVVVX9b13J9lCSEEJYsMGTIEAwaNAjr1q0ztgUEBGDSpEmIjY2t03/+/PnYs2cP0tPTjW1RUVE4ceIEUlJSAACPP/440tPT8fXXXxv7PPXUUzhy5AiSkpIaVVdRURGcnZ1RWFgIJycnS4ZERNSulZSUICMjA35+fjyqTS2iob+xxn5+W3SEpaysDKmpqQgPDzdpDw8PR3JystllUlJS6vQfPXo0jh07Zkxat9xyC1JTU3HkyBEAwNmzZxEfH4877rij3lpKS0tRVFRkMhEREVHbZFFgyc/Ph06ng4eHh0m7h4cHcnNzzS6Tm5trtn9FRQXy8/MBAPfeey+ef/553HLLLbCxsUGPHj1w6623YsGCBfXWEhsbC2dnZ+Pk4+NjyVCIiIhMdOvWDWvWrGmWdSUmJkKSJN511Yya9OC42lePCyEavKLcXP+a7YmJiXjxxRcRFxeHH374Abt27cLnn3+O559/vt51Lly4EIWFhcYpOzu7KUMhIqJWbMSIEYiOjm6WdR09ehSzZ89ulnVR87PoLiFXV1colco6R1Py8vLqHEWp4unpaba/SqUyXo2+ZMkSREZG4uGHHwYA9OvXD5cvX8bs2bOxaNEiKBR1c5VGo4FGo7GkfCIiameEENDpdFCprv5x5+bmdh0qoqay6AiLWq1GUFAQEhISTNoTEhIQGhpqdpmQkJA6/fft24fg4GDY2NgAAIqLi+uEEqVSCSEELLwmmIiImoEQAsVlFVaZGvvf/RkzZuDgwYN4/fXXIUkSJEnCu+++C0mSsHfvXgQHB0Oj0SApKQm//fYbJk6cCA8PDzg4OGDw4MHYv3+/yfpqnxKSJAnvvPMOJk+eDDs7O9xwww3Ys2dPk3+nO3fuRJ8+faDRaNCtWze8+uqrJvPj4uJwww03QKvVwsPDA/fcc49x3ieffIJ+/frB1tYWnTp1wqhRo3D58uUm19IaWfwclpiYGERGRiI4OBghISF4++23kZWVZXyuysKFC3H+/Hls3boVgOGOoLVr1yImJgazZs1CSkoKNm7ciG3bthnXOX78eKxevRoDBw7EkCFDcObMGSxZsgQTJkxolsf5EhGRZa6U6xD47F6rbPvk8tGwU1/94+n111/H6dOn0bdvXyxfvhwA8PPPPwMAnn76aaxatQrdu3dHhw4d8Pvvv2PcuHF44YUXoNVqsWXLFowfPx6nTp1C165d693Gc889hxUrVmDlypV48803MX36dJw7dw4dO3a0aEypqamYMmUKli1bhoiICCQnJ+PRRx9Fp06dMGPGDBw7dgxz5szBe++9h9DQUPz999/Gu2RzcnIwdepUrFixApMnT8bFixeRlJTU7v6H3uLAEhERgYKCAixfvhw5OTno27cv4uPj4evrC8Dwi635TBY/Pz/Ex8dj7ty5eOutt+Dt7Y033ngDd999t7HP4sWLIUkSFi9ejPPnz8PNzQ3jx4/Hiy++2AxDJCKitsjZ2RlqtRp2dnbw9PQEAPzyyy8AgOXLl+P222839u3UqRMGDBhgfP/CCy9g9+7d2LNnDx5//PF6tzFjxgxMnToVAPDSSy/hzTffxJEjRzBmzBiLal29ejVGjhyJJUuWAAB69eqFkydPYuXKlZgxYwaysrJgb2+PO++8E46OjvD19cXAgQMBGD5XKyoqcNdddxk/a/v162fR9tuCJj3p9tFHH8Wjjz5qdt67775bp2348OH44Ycf6i9CpcLSpUuxdOnSppRDRETNzNZGiZPLR1tt29cqODjY5P3ly5fx3HPP4fPPP8cff/yBiooKXLlypd6Hnlbp37+/8bW9vT0cHR2Nj5m3RHp6OiZOnGjSNnToUKxZswY6nQ633347fH190b17d4wZMwZjxowxnooaMGAARo4ciX79+mH06NEIDw/HPffcAxcXF4vraM2adJcQERG1bZIkwU6tssrUHN9jZG9vb/L+P//5D3bu3IkXX3wRSUlJOH78OPr164eysrIG11N1rWXN34ter7e4HnN309Y8pePo6IgffvgB27Ztg5eXF5599lkMGDAAFy5cgFKpREJCAr788ksEBgbizTffhL+/PzIyMiyuozVjYCEiolZLrVZDp9NdtV9SUhJmzJiByZMno1+/fvD09ERmZmbLF1gpMDAQ3333nUlbcnIyevXqZbxWU6VSYdSoUVixYgV+/PFHZGZm4ptvvgFgCEpDhw7Fc889h7S0NKjVauzevfu61S8H/LZmIiJqtbp164bDhw8jMzMTDg4O9R796NmzJ3bt2oXx48dDkiQsWbKkSUdKmuqpp57C4MGD8fzzzyMiIgIpKSlYu3Yt4uLiAACff/45zp49i2HDhsHFxQXx8fHQ6/Xw9/fH4cOH8fXXXyM8PBzu7u44fPgw/vrrLwQEBFy3+uWAR1iIiKjVmjdvHpRKJQIDA+Hm5lbvNSmvvfYaXFxcEBoaivHjx2P06NEYNGjQdatz0KBB+Oijj7B9+3b07dsXzz77LJYvX44ZM2YAADp06IBdu3bhtttuQ0BAANavX49t27ahT58+cHJywrfffotx48ahV69eWLx4MV599VWMHTv2utUvBxZ/+aFc8csPiYiahl9+SC3tun/5IREREZE1MLAQERFZKCoqCg4ODmanqgepUvPiRbdEREQWWr58OebNm2d2Hi9LaBkMLERERBZyd3eHu7u7tctoV3hKiIiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIjarW7dumHNmjXG95Ik4dNPP623f2ZmJiRJwvHjx69pu821HktcbWxyx9uaiYiIKuXk5MDFxaVZ1zljxgxcuHDBJCz4+PggJycHrq6uzbqttoyBhYiIqJKnp+d12Y5Sqbxu22oreEqIiIhapf/+97/o3Lkz9Hq9SfuECRPwwAMP4LfffsPEiRPh4eEBBwcHDB48GPv3729wnbVPmxw5cgQDBw6EVqtFcHAw0tLSTPrrdDrMnDkTfn5+sLW1hb+/P15//XXj/GXLlmHLli347LPPIEkSJElCYmKi2VNCBw8exE033QSNRgMvLy8sWLAAFRUVxvkjRozAnDlz8PTTT6Njx47w9PTEsmXLLP/FVfrpp59w2223wdbWFp06dcLs2bNx6dIl4/zExETcdNNNsLe3R4cOHTB06FCcO3cOAHDixAnceuutcHR0hJOTE4KCgnDs2LEm19IYDCxERFSXEEDZZetMQjSqxH/961/Iz8/HgQMHjG3//PMP9u7di+nTp+PSpUsYN24c9u/fj7S0NIwePRrjx49HVlZWo9Z/+fJl3HnnnfD390dqaiqWLVtW53H8er0eXbp0wUcffYSTJ0/i2WefxTPPPIOPPvoIADBv3jxMmTIFY8aMQU5ODnJychAaGlpnW+fPn8e4ceMwePBgnDhxAuvWrcPGjRvxwgsvmPTbsmUL7O3tcfjwYaxYsQLLly9HQkJCo8ZTU3FxMcaMGQMXFxccPXoUH3/8Mfbv34/HH38cAFBRUYFJkyZh+PDh+PHHH5GSkoLZs2dDkiQAwPTp09GlSxccPXoUqampWLBgAWxsbCyuwxI8JURERHWVFwMveVtn28/8Aajtr9qtY8eOGDNmDD788EOMHDkSAPDxxx+jY8eOGDlyJJRKJQYMGGDs/8ILL2D37t3Ys2eP8YO5IR988AF0Oh02bdoEOzs79OnTB7///jseeeQRYx8bGxs899xzxvd+fn5ITk7GRx99hClTpsDBwQG2trYoLS1t8BRQXFwcfHx8sHbtWkiShN69e+OPP/7A/Pnz8eyzz0KhMBxf6N+/P5YuXQoAuOGGG7B27Vp8/fXXuP322686ntpju3LlCrZu3Qp7e8Pveu3atRg/fjxeeeUV2NjYoLCwEHfeeSd69OgBAAgICDAun5WVhf/85z/o3bu3sZaWxiMsRETUak2fPh07d+5EaWkpAMMH8b333gulUonLly/j6aefRmBgIDp06AAHBwf88ssvjT7Ckp6ejgEDBsDOzs7YFhISUqff+vXrERwcDDc3Nzg4OGDDhg2N3kbNbYWEhBiPYADA0KFDcenSJfz+++/Gtv79+5ss5+Xlhby8PIu2VbW9AQMGGMNK1fb0ej1OnTqFjh07YsaMGcajUq+//jpycnKMfWNiYvDwww9j1KhRePnll/Hbb79ZXIOleISFiIjqsrEzHOmw1rYbafz48dDr9fjiiy8wePBgJCUlYfXq1QCA//znP9i7dy9WrVqFnj17wtbWFvfccw/KysoatW7RiFNTH330EebOnYtXX30VISEhcHR0xMqVK3H48OFGj6FqWzXDSs3t12yvfdpFkqQ61/A0dXs11wkAmzdvxpw5c/DVV19hx44dWLx4MRISEnDzzTdj2bJlmDZtGr744gt8+eWXWLp0KbZv347JkydbXEtjMbAQEVFdktSo0zLWZmtri7vuugsffPABzpw5g169eiEoKAgAkJSUhBkzZhg/RC9duoTMzMxGrzswMBDvvfcerly5AltbWwDA999/b9InKSkJoaGhePTRR41ttY82qNVq6HS6q25r586dJkEiOTkZjo6O6Ny5c6NrbqzAwEBs2bIFly9fNh5lOXToEBQKBXr16mXsN3DgQAwcOBALFy5ESEgIPvzwQ9x8880AgF69eqFXr16YO3cupk6dis2bN7doYOEpISIiatWmT5+OL774Aps2bcJ9991nbO/Zsyd27dqF48eP48SJE5g2bZpFRyOmTZsGhUKBmTNn4uTJk4iPj8eqVatM+vTs2RPHjh3D3r17cfr0aSxZsgRHjx416dOtWzf8+OOPOHXqFPLz81FeXl5nW48++iiys7PxxBNP4JdffsFnn32GpUuXIiYmxnj9SnOaPn06tFotHnjgAfzvf//DgQMH8MQTTyAyMhIeHh7IyMjAwoULkZKSgnPnzmHfvn04ffo0AgICcOXKFTz++ONITEzEuXPncOjQIRw9etTkGpeWwMBCRESt2m233YaOHTvi1KlTmDZtmrH9tddeg4uLC0JDQzF+/HiMHj0agwYNavR6HRwc8H//9384efIkBg4ciEWLFuGVV14x6RMVFYW77roLERERGDJkCAoKCkyOtgDArFmz4O/vb7zO5dChQ3W21blzZ8THx+PIkSMYMGAAoqKiMHPmTCxevNjC30bj2NnZYe/evfj7778xePBg3HPPPRg5ciTWrl1rnP/LL7/g7rvvRq9evTB79mw8/vjj+Pe//w2lUomCggLcf//96NWrF6ZMmYKxY8eaXHzcEiTRmJN0rUBRURGcnZ1RWFgIJycna5dDRNRqlJSUICMjA35+ftBqtdYuh9qghv7GGvv5zSMsREREJHsMLERERK3cBx98AAcHB7NTnz59rF1es+BdQkRERK3chAkTMGTIELPzWvoJtNcLAwsREVEr5+joCEdHR2uX0aJ4SoiIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIWq0RI0YgOjra2mVg2bJluPHGG61dRpvGwEJERHSN5s2bh6+//traZTTKjBkzMGnSJGuXYTEGFiIionqUlZU1qp+DgwM6derUwtU0zNy3QLclDCxERNQmlJWV4emnn0bnzp1hb2+PIUOGIDEx0Ti/oKAAU6dORZcuXWBnZ4d+/fph27ZtJusYMWIEHn/8ccTExMDV1RW33347EhMTIUkSvv76awQHB8POzg6hoaE4deqUcbnap4SqjmKsWrUKXl5e6NSpEx577DGTUJGTk4M77rgDtra28PPzw4cffohu3bphzZo1jRqvJElYv349Jk6cCHt7e7zwwgvQ6XSYOXMm/Pz8YGtrC39/f7z++usmdW7ZsgWfffYZJEmCJEnG39H58+cREREBFxcXdOrUCRMnTkRmZmajf/8tjU+6JSKiOoQQuFJxxSrbtlXZQpIki5d78MEHkZmZie3bt8Pb2xu7d+/GmDFj8NNPP+GGG25ASUkJgoKCMH/+fDg5OeGLL75AZGQkunfvbvJY+y1btuCRRx7BoUOHIIRAbm4uAGDRokV49dVX4ebmhqioKDz00EM4dOhQvfUcOHAAXl5eOHDgAM6cOYOIiAjceOONmDVrFgDg/vvvR35+PhITE2FjY4OYmBjk5eVZNOalS5ciNjYWr732GpRKJfR6Pbp06YKPPvoIrq6uSE5OxuzZs+Hl5YUpU6Zg3rx5SE9PR1FRETZv3gwA6NixI4qLi3HrrbciLCwM3377LVQqFV544QWMGTMGP/74I9RqtaW7o9kxsBARUR1XKq5gyIfmv5umpR2edhh2NnYWLfPbb79h27Zt+P333+Ht7Q3AcF3JV199hc2bN+Oll15C586dMW/ePOMyTzzxBL766it8/PHHJoGlZ8+eWLFihfF9VWB58cUXMXz4cADAggULcMcdd6CkpARardZsTS4uLli7di2USiV69+6NO+64A19//TVmzZqFX375Bfv378fRo0cRHBwMAHjnnXdwww03WDTuadOm4aGHHjJpe+6554yv/fz8kJycjI8++ghTpkyBg4MDbG1tUVpaCk9PT2O/999/HwqFAu+8844xLG7evBkdOnRAYmIiwsPDLaqrJTTplFBcXBz8/Pyg1WoRFBSEpKSkBvsfPHgQQUFB0Gq16N69O9avX1+nz4ULF/DYY4/By8sLWq0WAQEBiI+Pb0p5RETUzvzwww8QQqBXr14m31R88OBB/PbbbwAAnU6HF198Ef3790enTp3g4OCAffv2ISsry2RdVQGitv79+xtfe3l5AUCDR0T69OkDpVJpskxV/1OnTkGlUmHQoEHG+T179oSLi4tF4zZX6/r16xEcHAw3Nzc4ODhgw4YNdcZYW2pqKs6cOQNHR0fj765jx44oKSkx/v6szeIjLDt27EB0dDTi4uIwdOhQ/Pe//8XYsWNx8uRJdO3atU7/jIwMjBs3DrNmzcL777+PQ4cO4dFHH4WbmxvuvvtuAIbzjrfffjvc3d3xySefoEuXLsjOzm7zX+RERCRXtipbHJ522GrbtpRer4dSqURqaqpJSAAMF8QCwKuvvorXXnsNa9asQb9+/WBvb4/o6Og6F9ba29ub3UbNbz2uOgqh1+vrran2tyRLkmTsL4Qwu0x97fWpXetHH32EuXPn4tVXX0VISAgcHR2xcuVKHD7c8L7U6/UICgrCBx98UGeem5ubRTW1FIsDy+rVqzFz5kw8/PDDAIA1a9Zg7969WLduHWJjY+v0X79+Pbp27Wq8iCggIADHjh3DqlWrjIFl06ZN+Pvvv5GcnGzcwb6+vk0dExERXSNJkiw+LWNNAwcOhE6nQ15eHsLCwsz2SUpKwsSJE3HfffcBMHxI//rrrwgICLiepQIAevfujYqKCqSlpSEoKAgAcObMGVy4cOGa1puUlITQ0FA8+uijxrbaR0jUajV0Op1J26BBg7Bjxw64u7vDycnpmmpoKRadEiorK0Nqamqdc1nh4eFITk42u0xKSkqd/qNHj8axY8eMV0vv2bMHISEheOyxx+Dh4YG+ffvipZdeqvMLram0tBRFRUUmExERtU+9evXC9OnTcf/992PXrl3IyMjA0aNH8corrxgvL+jZsycSEhKQnJyM9PR0/Pvf/zZen3K99e7dG6NGjcLs2bNx5MgRpKWlYfbs2bC1bdoFx1V69uyJY8eOYe/evTh9+jSWLFmCo0ePmvTp1q0bfvzxR5w6dQr5+fkoLy/H9OnT4erqiokTJyIpKQkZGRk4ePAgnnzySfz+++/XOtxmYVFgyc/Ph06ng4eHh0m7h4dHvTs9NzfXbP+Kigrk5+cDAM6ePYtPPvkEOp0O8fHxWLx4MV599VW8+OKL9dYSGxsLZ2dn4+Tj42PJUIiIqI3ZvHkz7r//fjz11FPw9/fHhAkTcPjwYePnw5IlSzBo0CCMHj0aI0aMgKenp1UfoLZ161Z4eHhg2LBhmDx5MmbNmgVHR8d6L+JtjKioKNx1112IiIjAkCFDUFBQYHK0BQBmzZoFf39/43Uuhw4dgp2dHb799lt07doVd911FwICAvDQQw/hypUrsjniIgkLTpj98ccf6Ny5M5KTkxESEmJsf/HFF/Hee+/hl19+qbNMr1698OCDD2LhwoXGtkOHDuGWW25BTk4OPD090atXL5SUlCAjI8N47nH16tVYuXIlcnJyzNZSWlqK0tJS4/uioiL4+PigsLBQNr9cIqLWoOq/v1U3U5B1/P777/Dx8cH+/fsxcuRIa5fTrBr6GysqKoKzs/NVP78tuobF1dUVSqWyztGUvLy8OkdRqnh6eprtr1KpjE8F9PLygo2NjcmFUgEBAcjNzUVZWZnZ+781Gg00Go0l5RMREcnGN998g0uXLqFfv37IycnB008/jW7dumHYsGHWLk2WLDolpFarERQUhISEBJP2hIQEhIaGml0mJCSkTv99+/YhODjYeIHt0KFDcebMGZOrrU+fPg0vLy9ZPKyGiIiouZWXl+OZZ55Bnz59MHnyZLi5uRkfIvfBBx+Y3J5dc+rTp4+1S7cKi+8SiomJQWRkJIKDgxESEoK3334bWVlZiIqKAgAsXLgQ58+fx9atWwEYzqetXbsWMTExmDVrFlJSUrBx40aTxyE/8sgjePPNN/Hkk0/iiSeewK+//oqXXnoJc+bMaaZhEhERycvo0aMxevRos/MmTJhg8jC7mmrfLt1eWBxYIiIiUFBQgOXLlyMnJwd9+/ZFfHy88TbknJwckwfU+Pn5IT4+HnPnzsVbb70Fb29vvPHGG8ZbmgHAx8cH+/btw9y5c9G/f3907twZTz75JObPn98MQyQiImpdHB0d+SyyWiy66FbOGnvRDhERmaq6ILJbt26wtbX8oW1EV3PlyhVkZmZe00W3/LZmIqJ2ruoUQ3FxsZUrobaq6m/rWk5n8csPiYjaOaVSiQ4dOhi/58bOzu6aHl5GVEUIgeLiYuTl5aFDhw51vjbBEgwsRERk/Obehr7Mj6ipOnToYPLt0E3BwEJERJAkCV5eXnB3dzd+bQpRc6j9nLWmYmAhIiIjpVLZLB8uRM2NF90SERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkewxsBAREZHsNSmwxMXFwc/PD1qtFkFBQUhKSmqw/8GDBxEUFAStVovu3btj/fr19fbdvn07JEnCpEmTmlIaERERtUEWB5YdO3YgOjoaixYtQlpaGsLCwjB27FhkZWWZ7Z+RkYFx48YhLCwMaWlpeOaZZzBnzhzs3LmzTt9z585h3rx5CAsLs3wkRERE1GZJQghhyQJDhgzBoEGDsG7dOmNbQEAAJk2ahNjY2Dr958+fjz179iA9Pd3YFhUVhRMnTiAlJcXYptPpMHz4cDz44INISkrChQsX8Omnnza6rqKiIjg7O6OwsBBOTk6WDImIiIispLGf3xYdYSkrK0NqairCw8NN2sPDw5GcnGx2mZSUlDr9R48ejWPHjqG8vNzYtnz5cri5uWHmzJmNqqW0tBRFRUUmExEREbVNFgWW/Px86HQ6eHh4mLR7eHggNzfX7DK5ublm+1dUVCA/Px8AcOjQIWzcuBEbNmxodC2xsbFwdnY2Tj4+PpYMhYiIiFqRJl10K0mSyXshRJ22q/Wvar948SLuu+8+bNiwAa6uro2uYeHChSgsLDRO2dnZFoyAiIiIWhOVJZ1dXV2hVCrrHE3Jy8urcxSliqenp9n+KpUKnTp1ws8//4zMzEyMHz/eOF+v1xuKU6lw6tQp9OjRo856NRoNNBqNJeUTERFRK2XRERa1Wo2goCAkJCSYtCckJCA0NNTsMiEhIXX679u3D8HBwbCxsUHv3r3x008/4fjx48ZpwoQJuPXWW3H8+HGe6iEiIiLLjrAAQExMDCIjIxEcHIyQkBC8/fbbyMrKQlRUFADDqZrz589j69atAAx3BK1duxYxMTGYNWsWUlJSsHHjRmzbtg0AoNVq0bdvX5NtdOjQAQDqtBMREVH7ZHFgiYiIQEFBAZYvX46cnBz07dsX8fHx8PX1BQDk5OSYPJPFz88P8fHxmDt3Lt566y14e3vjjTfewN133918oyAiIqI2zeLnsMgVn8NCRETU+rTIc1iIiIiIrIGBhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSPgYWIiIhkj4GFiIiIZI+BhYiIiGSvSYElLi4Ofn5+0Gq1CAoKQlJSUoP9Dx48iKCgIGi1WnTv3h3r1683mb9hwwaEhYXBxcUFLi4uGDVqFI4cOdKU0oiIiKgNsjiw7NixA9HR0Vi0aBHS0tIQFhaGsWPHIisry2z/jIwMjBs3DmFhYUhLS8MzzzyDOXPmYOfOncY+iYmJmDp1Kg4cOICUlBR07doV4eHhOH/+fNNHRkRERG2GJIQQliwwZMgQDBo0COvWrTO2BQQEYNKkSYiNja3Tf/78+dizZw/S09ONbVFRUThx4gRSUlLMbkOn08HFxQVr167F/fff36i6ioqK4OzsjMLCQjg5OVkyJCIiIrKSxn5+W3SEpaysDKmpqQgPDzdpDw8PR3JystllUlJS6vQfPXo0jh07hvLycrPLFBcXo7y8HB07dqy3ltLSUhQVFZlMRERE1DZZFFjy8/Oh0+ng4eFh0u7h4YHc3Fyzy+Tm5prtX1FRgfz8fLPLLFiwAJ07d8aoUaPqrSU2NhbOzs7GycfHx5KhEBERUSvSpItuJUkyeS+EqNN2tf7m2gFgxYoV2LZtG3bt2gWtVlvvOhcuXIjCwkLjlJ2dbckQiIiIqBVRWdLZ1dUVSqWyztGUvLy8OkdRqnh6eprtr1Kp0KlTJ5P2VatW4aWXXsL+/fvRv3//BmvRaDTQaDSWlE9EREStlEVHWNRqNYKCgpCQkGDSnpCQgNDQULPLhISE1Om/b98+BAcHw8bGxti2cuVKPP/88/jqq68QHBxsSVlERETUxll8SigmJgbvvPMONm3ahPT0dMydOxdZWVmIiooCYDhVU/POnqioKJw7dw4xMTFIT0/Hpk2bsHHjRsybN8/YZ8WKFVi8eDE2bdqEbt26ITc3F7m5ubh06VIzDJGIiIhaO4tOCQFAREQECgoKsHz5cuTk5KBv376Ij4+Hr68vACAnJ8fkmSx+fn6Ij4/H3Llz8dZbb8Hb2xtvvPEG7r77bmOfuLg4lJWV4Z577jHZ1tKlS7Fs2bImDo2IiIjaCoufwyJXfA4LERFR69Miz2EhIiIisgYGFiIiIpI9BhYiIiKSPQYWIiIikj0GFiIiIpI9BhYiIiKSPQYWIiIikj0GFiIiIpI9BhYiIiKSPQYWIiIikj0GFiIiIpI9BhYiIiKSPQYWIiIikj0GFiIiIpI9BhYiIiKSPQYWIiIikj0GFiIiIpI9BhYiIiKSPZW1C5C7d//3Ln6/9Lu1yyAiahXUSjXu7H4nAjsFWrsUamMYWK5if9Z+nPjrhLXLICJqNd47+R7u6H4Hnhj4BDo7dLZ2OdRGSEIIYe0imkNRURGcnZ1RWFgIJyenZlvvztM7kVuc22zrIyJqyzIKM7A3cy8AwEZhg+kB0/Fwv4fhrHG2cmUkV439/GZgISKiZvVzwc947dhrOJx7GADgpHbC7P6zMbX3VKiVaitXR3LDwEJERFYjhMB357/D6tTVOHPhDACgs0NnzBk4B2P8xkAh8Z4PMmBgISIiq9Ppddjz2x6sTVuLvCt5AIDAToF4Kugp3OR1k5WrIzlgYCEiItkoLi/G++nvY9P/NuFy+WUAwLAuwzB30Fz0dOlp5erImhhYiIhIdgquFGD9ifX45PQnqBAVUEgKTO45GY/e+Cjc7dytXR5ZAQMLERHJVmZhJt5IewMJ5xIAAFqlFvf3uR8P9X0I9jb2Vq6OricGFiIikr3jecex6tgq4/OuOmo74pEBj+DuXnfDRmFj5eroemBgISKiVkEIga+zvsaaH9bgXNE5AEA3p26IHhSN27reBkmSrFwhtSQGFiIialXK9eX45PQnWH9iPf4u+RsAMNB9IGKCYnCj+43WLY5aDAMLERG1SpfKLmHzz5ux9eetKNGVAABu970dTw56Er5OvlaujpobAwsREbVqf17+E3En4vDpmU+hF3qoJBXG+I1BB00Ha5fWbt0XeF+zfz8UAwsREbUJp/85jTWpa5B0PsnapbR77497HwPcBjTrOhv7+c1vayYiIlnr5dILcaPicDT3KL7P+R5t5P+zWyV3W+s9K4eBhYiIWoXBnoMx2HOwtcsgK+G3TxEREZHsMbAQERGR7DGwEBERkewxsBAREZHsMbAQERGR7DGwEBERkew1KbDExcXBz88PWq0WQUFBSEpq+GE+Bw8eRFBQELRaLbp3747169fX6bNz504EBgZCo9EgMDAQu3fvbkppRERE1AZZHFh27NiB6OhoLFq0CGlpaQgLC8PYsWORlZVltn9GRgbGjRuHsLAwpKWl4ZlnnsGcOXOwc+dOY5+UlBREREQgMjISJ06cQGRkJKZMmYLDhw83fWRERETUZlj8aP4hQ4Zg0KBBWLdunbEtICAAkyZNQmxsbJ3+8+fPx549e5Cenm5si4qKwokTJ5CSkgIAiIiIQFFREb788ktjnzFjxsDFxQXbtm1rVF18ND8REVHr09jPb4uOsJSVlSE1NRXh4eEm7eHh4UhOTja7TEpKSp3+o0ePxrFjx1BeXt5gn/rWCQClpaUoKioymYiIiKhtsiiw5OfnQ6fTwcPDw6Tdw8MDubm5ZpfJzc0127+iogL5+fkN9qlvnQAQGxsLZ2dn4+Tj42PJUIiIiKgVadJFt5IkmbwXQtRpu1r/2u2WrnPhwoUoLCw0TtnZ2Y2un4iIiFoXi7780NXVFUqlss6Rj7y8vDpHSKp4enqa7a9SqdCpU6cG+9S3TgDQaDTQaDSWlE9EREStlEWBRa1WIygoCAkJCZg8ebKxPSEhARMnTjS7TEhICP7v//7PpG3fvn0IDg6GjY2NsU9CQgLmzp1r0ic0NLTRtVUdteG1LERERK1H1ef2Ve8BEhbavn27sLGxERs3bhQnT54U0dHRwt7eXmRmZgohhFiwYIGIjIw09j979qyws7MTc+fOFSdPnhQbN24UNjY24pNPPjH2OXTokFAqleLll18W6enp4uWXXxYqlUp8//33ja4rOztbAODEiRMnTpw4tcIpOzu7wc95i46wAIZbkAsKCrB8+XLk5OSgb9++iI+Ph6+vLwAgJyfH5Jksfn5+iI+Px9y5c/HWW2/B29sbb7zxBu6++25jn9DQUGzfvh2LFy/GkiVL0KNHD+zYsQNDhgxpdF3e3t7Izs6Go6Njg9e+WKqoqAg+Pj7Izs5uF7dLt6fxcqxtV3saL8fadrWX8QohcPHiRXh7ezfYz+LnsLQ37e35Lu1pvBxr29Wexsuxtl3tbbxXw+8SIiIiItljYCEiIiLZY2C5Co1Gg6VLl7abW6jb03g51rarPY2XY2272tt4r4bXsBAREZHs8QgLERERyR4DCxEREckeAwsRERHJHgMLERERyR4DC4C4uDj4+flBq9UiKCgISUlJDfY/ePAggoKCoNVq0b17d6xfv/46VXptYmNjMXjwYDg6OsLd3R2TJk3CqVOnGlwmMTERkiTVmX755ZfrVHXTLFu2rE7Nnp6eDS7TWvdrt27dzO6jxx57zGz/1rZPv/32W4wfPx7e3t6QJAmffvqpyXwhBJYtWwZvb2/Y2tpixIgR+Pnnn6+63p07dyIwMBAajQaBgYHYvXt3C42g8Roaa3l5OebPn49+/frB3t4e3t7euP/++/HHH380uM53333X7P4uKSlp4dE07Gr7dcaMGXVqvvnmm6+6XjnuV+Dq4zW3jyRJwsqVK+tdp1z3bUtp94Flx44diI6OxqJFi5CWloawsDCMHTvW5OsFasrIyMC4ceMQFhaGtLQ0PPPMM5gzZw527tx5nSu33MGDB/HYY4/h+++/R0JCAioqKhAeHo7Lly9fddlTp04hJyfHON1www3XoeJr06dPH5Oaf/rpp3r7tub9evToUZNxJiQkAAD+9a9/Nbhca9mnly9fxoABA7B27Vqz81esWIHVq1dj7dq1OHr0KDw9PXH77bfj4sWL9a4zJSUFERERiIyMxIkTJxAZGYkpU6bg8OHDLTWMRmlorMXFxfjhhx+wZMkS/PDDD9i1axdOnz6NCRMmXHW9Tk5OJvs6JycHWq22JYbQaFfbrwAwZswYk5rj4+MbXKdc9ytw9fHW3j+bNm2CJEkmX2Njjhz3bYtp9LcLtlE33XSTiIqKMmnr3bu3WLBggdn+Tz/9tOjdu7dJ27///W9x8803t1iNLSUvL08AEAcPHqy3z4EDBwQA8c8//1y/wprB0qVLxYABAxrdvy3t1yeffFL06NFD6PV6s/Nb6z4VQggAYvfu3cb3er1eeHp6ipdfftnYVlJSIpydncX69evrXc+UKVPEmDFjTNpGjx4t7r333mavualqj9WcI0eOCADi3Llz9fbZvHmzcHZ2bt7impm5sT7wwANi4sSJFq2nNexXIRq3bydOnChuu+22Bvu0hn3bnNr1EZaysjKkpqYiPDzcpD08PBzJyclml0lJSanTf/To0Th27BjKy8tbrNaWUFhYCADo2LHjVfsOHDgQXl5eGDlyJA4cONDSpTWLX3/9Fd7e3vDz88O9996Ls2fP1tu3rezXsrIyvP/++3jooYeu+iWgrXGf1paRkYHc3FyTfafRaDB8+PB6/w0D9e/vhpaRo8LCQkiShA4dOjTY79KlS/D19UWXLl1w5513Ii0t7foUeI0SExPh7u6OXr16YdasWcjLy2uwf1vZr3/++Se++OILzJw586p9W+u+bYp2HVjy8/Oh0+ng4eFh0u7h4YHc3Fyzy+Tm5prtX1FRgfz8/BartbkJIRATE4NbbrkFffv2rbefl5cX3n77bezcuRO7du2Cv78/Ro4ciW+//fY6Vmu5IUOGYOvWrdi7dy82bNiA3NxchIaGoqCgwGz/trJfP/30U1y4cAEzZsyot09r3afmVP07teTfcNVyli4jNyUlJViwYAGmTZvW4Bfj9e7dG++++y727NmDbdu2QavVYujQofj111+vY7WWGzt2LD744AN88803ePXVV3H06FHcdtttKC0trXeZtrBfAWDLli1wdHTEXXfd1WC/1rpvm0pl7QLkoPb/iQohGvy/U3P9zbXL2eOPP44ff/wR3333XYP9/P394e/vb3wfEhKC7OxsrFq1CsOGDWvpMpts7Nixxtf9+vVDSEgIevTogS1btiAmJsbsMm1hv27cuBFjx45t8GvaW+s+bYil/4abuoxclJeX495774Ver0dcXFyDfW+++WaTi1WHDh2KQYMG4c0338Qbb7zR0qU2WUREhPF13759ERwcDF9fX3zxxRcNfpC35v1aZdOmTZg+ffpVr0Vprfu2qdr1ERZXV1colco66TsvL69OSq/i6elptr9KpUKnTp1arNbm9MQTT2DPnj04cOAAunTpYvHyN998c6tL8Pb29ujXr1+9dbeF/Xru3Dns378fDz/8sMXLtsZ9CsB455cl/4arlrN0GbkoLy/HlClTkJGRgYSEhAaPrpijUCgwePDgVre/vby84Ovr22DdrXm/VklKSsKpU6ea9O+4te7bxmrXgUWtViMoKMh4V0WVhIQEhIaGml0mJCSkTv99+/YhODgYNjY2LVZrcxBC4PHHH8euXbvwzTffwM/Pr0nrSUtLg5eXVzNX17JKS0uRnp5eb92teb9W2bx5M9zd3XHHHXdYvGxr3KcA4OfnB09PT5N9V1ZWhoMHD9b7bxiof383tIwcVIWVX3/9Ffv3729SmBZC4Pjx461ufxcUFCA7O7vBulvrfq1p48aNCAoKwoABAyxetrXu20az1tW+crF9+3ZhY2MjNm7cKE6ePCmio6OFvb29yMzMFEIIsWDBAhEZGWnsf/bsWWFnZyfmzp0rTp48KTZu3ChsbGzEJ598Yq0hNNojjzwinJ2dRWJiosjJyTFOxcXFxj61x/vaa6+J3bt3i9OnT4v//e9/YsGCBQKA2LlzpzWG0GhPPfWUSExMFGfPnhXff/+9uPPOO4Wjo2Ob3K9CCKHT6UTXrl3F/Pnz68xr7fv04sWLIi0tTaSlpQkAYvXq1SItLc14Z8zLL78snJ2dxa5du8RPP/0kpk6dKry8vERRUZFxHZGRkSZ3/h06dEgolUrx8ssvi/T0dPHyyy8LlUolvv/+++s+vpoaGmt5ebmYMGGC6NKlizh+/LjJv+HS0lLjOmqPddmyZeKrr74Sv/32m0hLSxMPPvigUKlU4vDhw9YYolFDY7148aJ46qmnRHJyssjIyBAHDhwQISEhonPnzq1yvwpx9b9jIYQoLCwUdnZ2Yt26dWbX0Vr2bUtp94FFCCHeeust4evrK9RqtRg0aJDJbb4PPPCAGD58uEn/xMREMXDgQKFWq0W3bt3q/eOSGwBmp82bNxv71B7vK6+8Inr06CG0Wq1wcXERt9xyi/jiiy+uf/EWioiIEF5eXsLGxkZ4e3uLu+66S/z888/G+W1pvwohxN69ewUAcerUqTrzWvs+rboNu/b0wAMPCCEMtzYvXbpUeHp6Co1GI4YNGyZ++uknk3UMHz7c2L/Kxx9/LPz9/YWNjY3o3bu3LAJbQ2PNyMio99/wgQMHjOuoPdbo6GjRtWtXoVarhZubmwgPDxfJycnXf3C1NDTW4uJiER4eLtzc3ISNjY3o2rWreOCBB0RWVpbJOlrLfhXi6n/HQgjx3//+V9ja2ooLFy6YXUdr2bctRRKi8spCIiIiIplq19ewEBERUevAwEJERESyx8BCREREssfAQkRERLLHwEJERESyx8BCREREssfAQkRERLLHwEJERESyx8BCREREssfAQkRERLLHwEJERESyx8BCREREsvf/Kpd/daEYSdYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# put all together in a learner\n",
    "# (batch, d_seq, d_model)\n",
    "\n",
    "d_seq = 100 # dimension sequence\n",
    "d_vocab = 50304 # dimension vocabulary\n",
    "d_vec = 512 # dimension embedding vector\n",
    "d_model = 512 # dimension model input\n",
    "assert d_model == d_vec\n",
    "\n",
    "ds_param = {'train_param': {'transforms': {'tokens': [AsTensor()],\n",
    "                            'y': [AsTensor()],\n",
    "                            'position': [AsTensor()]},\n",
    "            'd_seq': d_seq,\n",
    "            #'n': 100000\n",
    "                           }}\n",
    "\n",
    "model_param = {'gpu': True,\n",
    "               'd_model': d_model,\n",
    "               'd_vocab': d_vocab, \n",
    "               'n_head': 8, \n",
    "               'num_layers': 6,\n",
    "               'd_seq': d_seq,\n",
    "               'd_vec': d_vec,\n",
    "               'embed_param': {'tokens': (d_vocab, d_vec, None, True), \n",
    "                               'y': (d_vocab, d_vec, None, True),\n",
    "                               'position': (d_seq, d_vec, None, True)}} \n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer',\n",
    "                 'report_interval': 1,\n",
    "                 'log_plot': False,\n",
    "                 'min_lr': .0025} # break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=CrossEntropyLoss,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=32, epochs=20, gpu=True, \n",
    "              save_model='gpt_test_model', load_model=None,\n",
    "              target='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f741604a-078e-4156-8a8c-73ce10437b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.ds_idx):  1\n",
      "data.nbytes:  24\n",
      "CDataset created...\n",
      "CModel loaded...\n",
      "model loaded from state_dict...\n",
      "running model on gpu...\n",
      "data1:  {'X1': tensor([[ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290]],\n",
      "       device='cuda:0'), 'X2': tensor([[  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466]],\n",
      "       device='cuda:0')}\n",
      "data1:  {'X1': tensor([[ 3237,   262, 11621,   257,  3800,   290,   477,   262,  1450,   290]],\n",
      "       device='cuda:0'), 'X2': tensor([[  262, 11621,   257,  3800,   290,   477,   262,  1450,   290,  1466]],\n",
      "       device='cuda:0')}\n",
      "data:  tensor([ 258,  979,  425,  323, 2367, 2984, 1272, 3382,   84, 5975],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     29\u001b[0m sample_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_seed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m88\u001b[39m,\n\u001b[1;32m     30\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m.7\u001b[39m,\u001b[38;5;241m.15\u001b[39m)}\n\u001b[1;32m     32\u001b[0m sched_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m.5\u001b[39m, \n\u001b[1;32m     33\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     34\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooldown\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m---> 36\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mLearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTinyShakes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m              \u001b[49m\u001b[43mGPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m              \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m              \u001b[49m\u001b[43mSampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSelector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m              \u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m              \u001b[49m\u001b[43mScheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m              \u001b[49m\u001b[43mCriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m              \u001b[49m\u001b[43mopt_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msched_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msched_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrit_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmetrics_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m              \u001b[49m\u001b[43mload_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt_test_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gpt/../cosmosis/learning.py:379\u001b[0m, in \u001b[0;36mLearn.__init__\u001b[0;34m(self, Datasets, Model, Sampler, Metrics, DataLoader, Optimizer, Scheduler, Criterion, ds_param, model_param, sample_param, opt_param, sched_param, crit_param, metrics_param, adapt, load_model, load_embed, save_model, batch_size, epochs, gpu, weights_only, target)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m no_grad():\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 379\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39minfer()\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_model:\n",
      "File \u001b[0;32m~/gpt/../cosmosis/learning.py:441\u001b[0m, in \u001b[0;36mLearn.run\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    438\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata: \u001b[39m\u001b[38;5;124m'\u001b[39m, data)\n\u001b[0;32m--> 441\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mmetric_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39my_pred\u001b[38;5;241m.\u001b[39mappend(y_pred)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gpt/../cosmosis/model.py:319\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    316\u001b[0m    \u001b[38;5;66;03m#else: X = cat([X, embedded], dim=-1)\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# X is a list of embedded inputs\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 319\u001b[0m     X \u001b[38;5;241m=\u001b[39m l(X[\u001b[38;5;241m0\u001b[39m], X[\u001b[38;5;241m1\u001b[39m], tgt_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_mask(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), tgt_is_causal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_head(X)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "ds_param = {'train_param': {'transforms': {'X1': [AsTensor()],\n",
    "                                           'X2': [AsTensor()]},\n",
    "                            'd_seq': 10,\n",
    "                            'prompt': 'All the worlds a stage and all the men and women merely'}}\n",
    "\n",
    "model_param = {'device': 'cuda',\n",
    "               'd_model': 32, # matches embedding dimension\n",
    "               'd_vocab': 50304, # matches embedding vocab\n",
    "               'n_head': 4, \n",
    "               'num_layers': 3,\n",
    "               'linear_head': True,\n",
    "               'probs': False,\n",
    "               'tokens': False,\n",
    "               'transpose': True, \n",
    "               'embed_param': {'X1': (50304, 32, None, True),\n",
    "                               'X2': (50304, 32, None, True)}} \n",
    "\n",
    "                                       \n",
    "metrics_param = {'metric_name': 'transformer',\n",
    "                 'report_interval': 10,\n",
    "                 'log_plot': True,\n",
    "                 'min_lr': .005} # break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([TinyShakes], \n",
    "              GPT,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=None,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=1, epochs=10, gpu=True, \n",
    "              load_model='gpt_test_model.pth', target='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51656cf2-5d52-42f2-b815-0403fdf53f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
